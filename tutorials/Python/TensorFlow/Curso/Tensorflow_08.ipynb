{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66d01e0a",
   "metadata": {},
   "source": [
    "## Introduction to NLP in tensorflow "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0803b067",
   "metadata": {},
   "source": [
    "Nlp problems are also defined as seq to seq problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e718922f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 11:17:58.588090: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-27 11:17:58.588123: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Get helper functions \n",
    "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves,compare_historys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "861ef3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset used is Kaggle introduction to NLP, disaster classification\n",
    "#!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
    "    \n",
    "#Data extra, por se a cobertura \n",
    "#!wget https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccf571be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unzip_data(\"nlp_getting_started.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1623f98b",
   "metadata": {},
   "source": [
    "### Visualizing the text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e38f380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "302910ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1d2ffae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74911e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle training dataframe \n",
    "train_df_shuffled = train_df.sample(frac=1,random_state=42)\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2f8204b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa48b1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b270080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f268b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0 {not real disaster}\n",
      "Text: \n",
      " \n",
      " Free Ebay Sniping RT? http://t.co/RqIPGQslT6 Chevrolet : Avalanche Ltz Lifted 4x4 Truck ?Please Favorite &amp; Share\n",
      "------\n",
      "Target: 1 {real_disaster}\n",
      "Text: \n",
      " \n",
      " Chiasson Sens can't come to deal #ColoradoAvalanche #Avalanche http://t.co/2bk7laGMa9 http://t.co/bkDGCfsuiQ\n",
      "------\n",
      "Target: 0 {not real disaster}\n",
      "Text: \n",
      " \n",
      " Paul Rudd Emile Hirsch David Gordon Green 'Prince Avalanche' Q&amp;A | Filmmakers at Google http://t.co/e4QonKzndZ  #entretenimento #Video\n",
      "------\n",
      "Target: 0 {not real disaster}\n",
      "Text: \n",
      " \n",
      " Great one time deal on all Avalanche music and with purchase get a Neal Rigga shirt http://t.co/4VIRXkgMpC\n",
      "------\n",
      "Target: 0 {not real disaster}\n",
      "Text: \n",
      " \n",
      " .@bigperm28 was drafted by the @Avalanche in 2005 (rd. 4 #124) overall. Played last season in @UtahGrizz. http://t.co/gPGTAfMKt0\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "random_index = random.randint(0,len(train_df)-5)\n",
    "for row in train_df[random_index-5:random_index].itertuples():\n",
    "    text,target = row[-2:]\n",
    "    print(f\"Target: {target}\", \"{real_disaster}\" if target > 0 else \"{not real disaster}\"   )\n",
    "    print(f\"Text: \\n \\n {text}\")\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c57ceaf",
   "metadata": {},
   "source": [
    "### Create validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53cfd50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1442257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences,val_sentences,train_labels,val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
    "                                                                          train_df_shuffled[\"target\"].to_numpy(),\n",
    "                                                                          test_size=0.1,random_state=42\n",
    "                                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9fb5c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 762, 6851, 762)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences),len(val_sentences),len(train_labels),len(val_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bafa5aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "        'Imagine getting flattened by Kurt Zouma',\n",
       "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
       "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
       "        'destroy the free fandom honestly',\n",
       "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
       "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
       "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
       "       dtype=object),\n",
       " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chech the first 10 samples \n",
    "train_sentences[:10],train_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc45d74a",
   "metadata": {},
   "source": [
    "### Convert text into numbers (let's start with tokenization )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b191a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd24d465",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 11:18:04.976957: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-27 11:18:04.977000: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-27 11:18:04.977034: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (iT28200): /proc/driver/nvidia/version does not exist\n",
      "2022-06-27 11:18:04.978509: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "text_vectorizer = TextVectorization(max_tokens = None,#how many words\n",
    "                                    standardize = \"lower_and_strip_punctuation\",\n",
    "                                    split = \"whitespace\",\n",
    "                                    ngrams = None,\n",
    "                                    output_mode = \"int\",\n",
    "                                    output_sequence_length = None,\n",
    "                                    pad_to_max_tokens = None\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b93f8d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the average number of tokens in the training tweets \n",
    "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0297ddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stup text vectorization variables \n",
    "max_vocab_length = 10000\n",
    "max_length = 15 # in words \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d82fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer = TextVectorization(max_tokens = max_vocab_length,#how many words\n",
    "                                    output_mode = \"int\",\n",
    "                                    output_sequence_length = max_length,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc2e788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the text vectorizer to the training text \n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ad31db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[   3, 5900,    1,   17,    2,  119,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0]])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a sample sentence and tokenize it\n",
    "sample_sentence = \"A cow staring at the train\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9333bf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: \n",
      " \n",
      " Cyclone by Double G would be the cherry on top to this outfit! #OOTD #DoubleGhats http://t.co/JSuHuPz6Vp http://t.co/N5vrFFRbo3\n",
      "\n",
      " Vectorized_version: \n",
      "\n",
      " [[ 582   18 1302 2981   78   21    2 5993   11  212    5   19 4975    1\n",
      "     1]]\n"
     ]
    }
   ],
   "source": [
    "#Choose sentence from the training set and tokenize it \n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text: \\n \\n {random_sentence}\\n\\n Vectorized_version: \\n\\n {text_vectorizer([random_sentence]).numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "995f30c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique words in the vocabulary \n",
    "words_in_vocab = text_vectorizer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de67e7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'the', 'a', 'in'] are the top 5 words . \n",
      " ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1'] are the bottom_5_words \n"
     ]
    }
   ],
   "source": [
    "# Top 5 words and bottom 5 words \n",
    "print(f\"{words_in_vocab[:5]} are the top 5 words . \\n {words_in_vocab[-5:]} are the bottom_5_words \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0b1c33",
   "metadata": {},
   "source": [
    "### Create an embedding using an embedding layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47962d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.embedding.Embedding at 0x7f5ba65a8c40>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers \n",
    "\n",
    "embedding = layers.Embedding(input_dim = max_vocab_length,\n",
    "                            output_dim = 128,\n",
    "                            input_length = max_length)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "010d5db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      " I may have gotten a little too exited over my (home made) lava lamp. Through source http://t.co/nxTTd9NrUx http://t.co/iRQj3ZKCUz\n",
      "\n",
      " Embedded version: \n",
      " [[[ 0.00414246  0.04386207  0.02549699 ...  0.04178858  0.04061863\n",
      "    0.02668012]\n",
      "  [-0.00554769  0.01225854 -0.04317594 ... -0.01149576  0.01513142\n",
      "   -0.04350711]\n",
      "  [ 0.00829574  0.01988443  0.0258964  ...  0.00654578 -0.0091311\n",
      "   -0.0354569 ]\n",
      "  ...\n",
      "  [-0.01554769  0.03655053 -0.00053646 ... -0.02956824  0.02233976\n",
      "   -0.01074396]\n",
      "  [-0.03043287 -0.03696551  0.00129926 ...  0.00919835 -0.04280874\n",
      "   -0.02172144]\n",
      "  [ 0.00134876  0.00422161 -0.04985073 ...  0.00791746  0.01270728\n",
      "    0.0166094 ]]]\n"
     ]
    }
   ],
   "source": [
    "#Get a random sentence from the training set \n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n {random_sentence}\\\n",
    "\\n\\n Embedded version: \\n {embedding(text_vectorizer([random_sentence]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30b9bbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 0.00414246  0.04386207  0.02549699  0.01061247  0.03368266  0.01306986\n",
      " -0.0256884   0.03540336  0.00523617 -0.0356666   0.03919699 -0.03507842\n",
      "  0.03785847 -0.01957841  0.04544142 -0.02529737  0.01131345 -0.01562642\n",
      "  0.00147389  0.03522891  0.01833804 -0.02758596 -0.04944995  0.04883112\n",
      "  0.01348174 -0.03349417 -0.02412988 -0.01656201 -0.00438207  0.03259074\n",
      " -0.03898363  0.04933542 -0.01638378 -0.00086443 -0.02341137 -0.0028702\n",
      "  0.02487585  0.04454825 -0.03922411 -0.01076342  0.02179594 -0.04935573\n",
      "  0.03556644  0.04225941  0.04844321  0.01889237  0.03445286 -0.03826291\n",
      " -0.02382511  0.03009716 -0.00536889 -0.03412162  0.03189759 -0.00894561\n",
      "  0.03149301 -0.01079579  0.04134056  0.02392921 -0.01837412  0.01835365\n",
      "  0.03700713  0.00725009 -0.00419511 -0.02158771  0.04367002 -0.03925779\n",
      " -0.02096289 -0.04367478 -0.02803253 -0.04721184 -0.03216223 -0.01302439\n",
      "  0.01696888  0.02452937  0.01825181  0.0011449  -0.02308748 -0.03916782\n",
      "  0.01718913  0.01904109 -0.01059987 -0.03793144  0.04137639  0.00823651\n",
      "  0.0490958   0.01551628 -0.04296833  0.04026732  0.01164852 -0.03859957\n",
      "  0.04882417  0.04604865  0.02892209 -0.04345815  0.04274348 -0.03455223\n",
      " -0.04611757 -0.01561357  0.02909836 -0.0447267  -0.01894546  0.03491044\n",
      " -0.02025733  0.00839655 -0.02976915  0.02679567  0.03730898  0.04650444\n",
      " -0.02371869 -0.0262719   0.02231754  0.00021117  0.03667188  0.02599968\n",
      " -0.01232115  0.00698391 -0.04500024 -0.01364315  0.00580866 -0.04233999\n",
      " -0.00101592 -0.04096399  0.04989577 -0.00911469 -0.01707732  0.04178858\n",
      "  0.04061863  0.02668012], shape=(128,), dtype=float32) (128,)\n",
      "I may have gotten a little too exited over my (home made) lava lamp. Through source http://t.co/nxTTd9NrUx http://t.co/iRQj3ZKCUz\n"
     ]
    }
   ],
   "source": [
    "#Check a single token embedding \n",
    "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
    "print(sample_embed[0][0], sample_embed[0][0].shape)\n",
    "print(random_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fab3b4",
   "metadata": {},
   "source": [
    "## Modelling a text dataset and running some experiments "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16abe2ee",
   "metadata": {},
   "source": [
    "Model_0 : Naive-Bayes with tf-idf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f48b969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "#Create tokenization and model pipeline \n",
    "model_0 = Pipeline([\n",
    "    (\"tfidf\",TfidfVectorizer()), #Convert words to numbers using tfidf\n",
    "    (\"clf\",MultinomialNB()) #model the text\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d5397f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.fit(train_sentences,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc890344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7926509186351706"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_score = model_0.score(val_sentences,val_labels)\n",
    "baseline_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00aa9ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions \n",
    "baseline_preds = model_0.predict(val_sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398fd8e1",
   "metadata": {},
   "source": [
    "### Creating an evaluation function for the experiments \n",
    "\n",
    "There are different metrics, so trucutrucu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa068c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "253f6d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_results(y_true,y_pred):\n",
    "    \"\"\"Calculartes model accuracy, precission \n",
    "    recall and F1-score \n",
    "    \"\"\"\n",
    "    #Accuracy \n",
    "    model_accuracy = accuracy_score(y_true,y_pred)*100\n",
    "    #Precision, recall and F1-score weighted \n",
    "    model_precision,model_recall,model_f1,_ = precision_recall_fscore_support(y_true,y_pred,average=\"weighted\")\n",
    "    model_results = {\"accuracy\":model_accuracy,\n",
    "                    \"precision\":model_precision,\n",
    "                    \"recall\":model_recall,\n",
    "                    \"f1\":model_f1}\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "727212db",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = calculate_results(val_labels,baseline_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72683a5",
   "metadata": {},
   "source": [
    "### Model_1 : Feed forward neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ec8064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Firstly, create a tensorboard callback to track results \n",
    "from helper_functions import create_tensorboard_callback\n",
    "#Create a directory to save tensorboard logs \n",
    "SAVE_DIR = \"model_logs \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81412e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build model with the functional API \n",
    "from tensorflow.keras import layers\n",
    "inputs = layers.Input(shape=(1,),dtype=tf.string)\n",
    "x = text_vectorizer(inputs) # turn the input text into numbers\n",
    "x = embedding(x)\n",
    "x = layers.GlobalMaxPool1D()(x)#condense feature vector\n",
    "outputs = layers.Dense(1,activation=\"sigmoid\")(x)#Create the output layer\n",
    "model_1 = tf.keras.Model(inputs,outputs,name=\"model_1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c2df8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df06e088",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile model\n",
    "model_1.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "220a933c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs /model_1/20220627-111807\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 5s 18ms/step - loss: 0.6394 - accuracy: 0.6539 - val_loss: 0.5752 - val_accuracy: 0.7572\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.4716 - accuracy: 0.8256 - val_loss: 0.4746 - val_accuracy: 0.7835\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.3443 - accuracy: 0.8740 - val_loss: 0.4508 - val_accuracy: 0.7887\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 0.2612 - accuracy: 0.9070 - val_loss: 0.4548 - val_accuracy: 0.7900\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 5s 25ms/step - loss: 0.2008 - accuracy: 0.9314 - val_loss: 0.4686 - val_accuracy: 0.7913\n"
     ]
    }
   ],
   "source": [
    "model_1_history = model_1.fit(x=train_sentences,\n",
    "                              y=train_labels,\n",
    "                             epochs=5,\n",
    "                             validation_data=(val_sentences,val_labels),\n",
    "                             callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
    "                                                                   experiment_name=\"model_1\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f250c4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4686124324798584, 0.7913385629653931]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(val_sentences,val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d93ed5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "model_1_results = calculate_results(val_labels,tf.round(model_1.predict(val_sentences)).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "522c35c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False,  True])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28638b29",
   "metadata": {},
   "source": [
    "Tremendias "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977fe62b",
   "metadata": {},
   "source": [
    "### Visualize learned embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4df2bba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the vocabulary from text vectorization \n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "len(words_in_vocab),words_in_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "738a3b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ef98c21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the weight matrix of the embedding layer\n",
    "embed_weights = model_1.get_layer(\"embedding\").get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c8311632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10000, 128)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(embed_weights).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de2c50d",
   "metadata": {},
   "source": [
    "### Using the projector tool from tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "64582cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create embedding files (from word embeddings tensorflow documentation)\n",
    "import io\n",
    "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index, word in enumerate(words_in_vocab):\n",
    "  if index == 0:\n",
    "    continue  # skip 0, it's padding.\n",
    "  vec = embed_weights[0][index]\n",
    "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "  out_m.write(word + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66cee15",
   "metadata": {},
   "source": [
    "### Recurrent Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "754e517c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_2 : LSTM\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,),dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "#print(x.shape)\n",
    "x = layers.LSTM(units=64,return_sequences=True)(x)\n",
    "#print(x.shape)\n",
    "x = layers.LSTM(64)(x)\n",
    "#print(x.shape)\n",
    "x = layers.Dense(64,activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "model_2 = tf.keras.Model(inputs,outputs,name=\"model_2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc3eccb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 15, 64)            49408     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,366,657\n",
      "Trainable params: 1,366,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0afa7145",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model \n",
    "model_2.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a6088bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs /model_2/20220627-111831\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 14s 46ms/step - loss: 0.3764 - accuracy: 0.8374 - val_loss: 0.4519 - val_accuracy: 0.7953\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 10s 44ms/step - loss: 0.2437 - accuracy: 0.9031 - val_loss: 0.5898 - val_accuracy: 0.7808\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 8s 37ms/step - loss: 0.1716 - accuracy: 0.9378 - val_loss: 0.5858 - val_accuracy: 0.7848\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 10s 44ms/step - loss: 0.1337 - accuracy: 0.9524 - val_loss: 0.7510 - val_accuracy: 0.7782\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 10s 45ms/step - loss: 0.1019 - accuracy: 0.9648 - val_loss: 0.9947 - val_accuracy: 0.7743\n"
     ]
    }
   ],
   "source": [
    "history_2 = model_2.fit(x=train_sentences,\n",
    "                       y=train_labels,\n",
    "                       epochs=5,\n",
    "                       validation_data=(val_sentences,val_labels),\n",
    "                       callbacks=[create_tensorboard_callback(SAVE_DIR,\"model_2\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "19a883ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "model_2_preds = tf.squeeze(tf.round(model_2.predict(val_sentences))).numpy()\n",
    "model_2_results = calculate_results(val_labels,model_2_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f1784339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.42782152230971,\n",
       " 'precision': 0.7786304709648849,\n",
       " 'recall': 0.7742782152230971,\n",
       " 'f1': 0.7711035650901983}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "87f57582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_3 : GRU\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,),dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "#print(x.shape)\n",
    "#x = layers.GRU(units=64,return_sequences=True)(x)\n",
    "#x = layers.LSTM(units=64,return_sequences=True)(x)\n",
    "#print(x.shape)\n",
    "x = layers.GRU(64)(x)\n",
    "#print(x.shape)\n",
    "#x = layers.Dense(64,activation=\"relu\")(x)\n",
    "#x = layers.GlobalAveragePooling1D()(x)\n",
    "outputs = layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "model_3 = tf.keras.Model(inputs,outputs,name=\"model_3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4fcdc223",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model \n",
    "model_3.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e387f41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs /model_3/20220627-111923\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 10s 34ms/step - loss: 0.2199 - accuracy: 0.9045 - val_loss: 0.7634 - val_accuracy: 0.7769\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 7s 32ms/step - loss: 0.1002 - accuracy: 0.9641 - val_loss: 0.8053 - val_accuracy: 0.7808\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 7s 35ms/step - loss: 0.0788 - accuracy: 0.9710 - val_loss: 0.8300 - val_accuracy: 0.7795\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 6s 29ms/step - loss: 0.0619 - accuracy: 0.9753 - val_loss: 0.8976 - val_accuracy: 0.7717\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 7s 32ms/step - loss: 0.0556 - accuracy: 0.9759 - val_loss: 1.0664 - val_accuracy: 0.7533\n"
     ]
    }
   ],
   "source": [
    "history_3 = model_3.fit(x=train_sentences,\n",
    "                       y=train_labels,\n",
    "                       epochs=5,\n",
    "                       validation_data=(val_sentences,val_labels),\n",
    "                       callbacks=[create_tensorboard_callback(SAVE_DIR,\"model_3\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7274b17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "model_3_preds = tf.squeeze(tf.round(model_3.predict(val_sentences))).numpy()\n",
    "model_3_results = calculate_results(val_labels,model_3_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0a5b8123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 75.32808398950131,\n",
       " 'precision': 0.753004229734441,\n",
       " 'recall': 0.7532808398950132,\n",
       " 'f1': 0.7530956268877401}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6e76c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model_4: Bidirectional RNN\n",
    "inputs = layers.Input(shape=(1,),name=\"inputs\",dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64,return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64,))(x)\n",
    "outputs = layers.Dense(1,activation =tf.keras.activations.sigmoid)(x)\n",
    "model_4 = tf.keras.Model(inputs,outputs,name=\"model_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "816927c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 15, 128)          98816     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 128)              98816     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,477,761\n",
      "Trainable params: 1,477,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "df22116c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs /model_4/20220627-112003\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 19s 52ms/step - loss: 0.1294 - accuracy: 0.9441 - val_loss: 0.9253 - val_accuracy: 0.7677\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 9s 40ms/step - loss: 0.0589 - accuracy: 0.9745 - val_loss: 1.3129 - val_accuracy: 0.7651\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 12s 55ms/step - loss: 0.0514 - accuracy: 0.9784 - val_loss: 1.4748 - val_accuracy: 0.7585\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 9s 43ms/step - loss: 0.0471 - accuracy: 0.9784 - val_loss: 1.7912 - val_accuracy: 0.7480\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 13s 59ms/step - loss: 0.0460 - accuracy: 0.9785 - val_loss: 1.2888 - val_accuracy: 0.7717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5b79029c10>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=[\"accuracy\"])\n",
    "model_4.fit(x=train_sentences,\n",
    "           y=train_labels,\n",
    "           epochs=5,\n",
    "           validation_data=(val_sentences,val_labels),\n",
    "           callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
    "                                                experiment_name=\"model_4\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "96dee922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 2s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "model_4_results = calculate_results(val_labels,tf.round(model_4.predict(val_sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f5ec92c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.16535433070865,\n",
       " 'precision': 0.7751367943413853,\n",
       " 'recall': 0.7716535433070866,\n",
       " 'f1': 0.7687482528669142}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287225bc",
   "metadata": {},
   "source": [
    "### Convolutional NN for text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "695c25b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model_5: Conv1D\n",
    "embedding_tst = embedding(text_vectorizer([\"this is a test sentence\"]))\n",
    "conv_1d = layers.Conv1D(filters=32,\n",
    "                       kernel_size=5,\n",
    "                       activation=\"relu\",\n",
    "                       padding=\"same\")\n",
    "conv_1d_output = conv_1d(embedding_tst)\n",
    "max_pool = layers.GlobalMaxPool1D()\n",
    "max_pool_output =max_pool(conv_1d_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9ec8d8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 15, 128]), TensorShape([1, 15, 32]), TensorShape([1, 32]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_tst.shape,conv_1d_output.shape,max_pool_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e8859661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[-0.04627262,  0.00919561, -0.06574056, ..., -0.07419406,\n",
       "         -0.05252943, -0.05278938],\n",
       "        [ 0.01751778, -0.02824653, -0.05097576, ..., -0.06892952,\n",
       "         -0.0286429 , -0.03931302],\n",
       "        [ 0.05554759, -0.03847493, -0.03722861, ..., -0.04787545,\n",
       "         -0.05433097, -0.04807238],\n",
       "        ...,\n",
       "        [ 0.09965701, -0.02326744, -0.04207201, ..., -0.04974445,\n",
       "         -0.05307342, -0.04211177],\n",
       "        [ 0.09965701, -0.02326744, -0.04207201, ..., -0.04974445,\n",
       "         -0.05307342, -0.04211177],\n",
       "        [ 0.09965701, -0.02326744, -0.04207201, ..., -0.04974445,\n",
       "         -0.05307342, -0.04211177]]], dtype=float32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "582d8262",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(1,),dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.Conv1D(filters= 64,\n",
    "                 kernel_size = 5,\n",
    "                 activation = \"relu\",\n",
    "                 )(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "x = layers.Dense(64,activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "model_5 = tf.keras.Model(inputs,outputs,name=\"model_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "13d16b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "74fa7249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 11, 64)            41024     \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Glo  (None, 64)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,325,249\n",
      "Trainable params: 1,325,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b07e3b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs /model_5/20220627-112106\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 6s 24ms/step - loss: 0.1416 - accuracy: 0.9515 - val_loss: 0.9266 - val_accuracy: 0.7690\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.0573 - accuracy: 0.9778 - val_loss: 1.0932 - val_accuracy: 0.7638\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 21ms/step - loss: 0.0415 - accuracy: 0.9809 - val_loss: 1.2469 - val_accuracy: 0.7612\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 7s 34ms/step - loss: 0.0349 - accuracy: 0.9826 - val_loss: 1.4815 - val_accuracy: 0.7625\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 8s 35ms/step - loss: 0.0333 - accuracy: 0.9832 - val_loss: 1.5891 - val_accuracy: 0.7572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5b53fcf190>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.fit(x=train_sentences,\n",
    "           y=train_labels,\n",
    "           epochs=5,\n",
    "           validation_data=(val_sentences,val_labels),\n",
    "           callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
    "                                                 \"model_5\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "153ac61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model_5_results = calculate_results(val_labels,tf.round(model_5.predict(val_sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "08e7cc5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 75.7217847769029,\n",
       " 'precision': 0.7599832409812126,\n",
       " 'recall': 0.7572178477690289,\n",
       " 'f1': 0.7542079441072491}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfa1b12",
   "metadata": {},
   "source": [
    "### Model 6 Tensorflow hub feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d3f1b6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 0.06363875  0.06158425  0.02907713  0.01009343  0.00141239 -0.04822049\n",
      "  0.02682629  0.05565713  0.04665004  0.04489125  0.06711517  0.07163592\n",
      " -0.03868155  0.01240229 -0.06372787 -0.07787154  0.03454241  0.01807402\n",
      " -0.02946401 -0.00045595  0.00741567 -0.02742441  0.00801203  0.04649784\n",
      " -0.00310454  0.0518339   0.0507908   0.03404064 -0.08344434 -0.03078072\n",
      " -0.05472489 -0.06944979  0.03503908 -0.07366852 -0.05068438 -0.03965442\n",
      " -0.06214795 -0.01490314  0.01412074 -0.0173247  -0.00050386  0.06811386\n",
      " -0.05652634 -0.06010103 -0.08503088  0.06577724 -0.06609759 -0.0326493\n",
      "  0.01809361 -0.01892868], shape=(50,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "embed_samples = embed([sample_sentence,\n",
    "                      \"Omg is that the fucking akab\"])\n",
    "print(embed_samples[0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7ff0a548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a keras layer using the pretrained layer\n",
    "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                       input_shape= [],\n",
    "                                       dtype = tf.string,\n",
    "                                       trainable=False,\n",
    "                                       name=\"USE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "61dc91dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6 = tf.keras.Sequential([\n",
    "    sentence_encoder_layer,\n",
    "    layers.Dense(64,activation=\"relu\"),\n",
    "    layers.Dense(1,activation=\"sigmoid\",name=\"output_layer\")\n",
    "],name=\"model_6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ad48f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "49c1963a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6ba525bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs /model_6/20220627-112151\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 9s 21ms/step - loss: 0.5023 - accuracy: 0.7873 - val_loss: 0.4502 - val_accuracy: 0.8031\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 5s 21ms/step - loss: 0.4142 - accuracy: 0.8152 - val_loss: 0.4368 - val_accuracy: 0.8097\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 0.4009 - accuracy: 0.8212 - val_loss: 0.4329 - val_accuracy: 0.8123\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.3935 - accuracy: 0.8246 - val_loss: 0.4284 - val_accuracy: 0.8150\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 5s 24ms/step - loss: 0.3874 - accuracy: 0.8266 - val_loss: 0.4256 - val_accuracy: 0.8215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5b534434c0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6.fit(x=train_sentences,\n",
    "           y=train_labels,\n",
    "           epochs=5,\n",
    "           validation_data=(val_sentences,val_labels),\n",
    "           callbacks=[create_tensorboard_callback(SAVE_DIR,\"model_6\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "086a5086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 82.1522309711286,\n",
       " 'precision': 0.8241317499642585,\n",
       " 'recall': 0.821522309711286,\n",
       " 'f1': 0.82000293386527}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6_results = calculate_results(val_labels,tf.round(model_6.predict(val_sentences)))\n",
    "model_6_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356a4672",
   "metadata": {},
   "source": [
    "### Model 7 , TF Hub , pretrained USE with 10 percent of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "04dc21e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[45, 941, 86, 3161]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " random.choices(range(len(train_sentences)),k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1c6aad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_limit = int(0.1*len(train_sentences))\n",
    "rd_indexes = random.choices(range(len(train_sentences)),k=split_limit)\n",
    "train_sentences_10_percent = train_sentences[rd_indexes]\n",
    "train_label_10_percent = train_labels[rd_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4996f832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4291970802919708"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(train_label_10_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d5e51f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7 = tf.keras.Sequential([\n",
    "    sentence_encoder_layer,\n",
    "    layers.Dense(64,activation=\"relu\"),\n",
    "    layers.Dense(1,activation=\"sigmoid\")\n",
    "],name=\"model_7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a005e0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "faa1c4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs /model_7/20220627-112219\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 3s 48ms/step - loss: 0.6688 - accuracy: 0.6949 - val_loss: 0.6451 - val_accuracy: 0.7441\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.6024 - accuracy: 0.8146 - val_loss: 0.5878 - val_accuracy: 0.7782\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.5285 - accuracy: 0.8117 - val_loss: 0.5345 - val_accuracy: 0.7782\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.4635 - accuracy: 0.8131 - val_loss: 0.5003 - val_accuracy: 0.7848\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 1s 43ms/step - loss: 0.4189 - accuracy: 0.8263 - val_loss: 0.4849 - val_accuracy: 0.7769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5b530c9340>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7.fit(x=train_sentences_10_percent,\n",
    "           y=train_label_10_percent,\n",
    "           epochs=5,\n",
    "           validation_data=(val_sentences,val_labels),\n",
    "           callbacks=[create_tensorboard_callback(SAVE_DIR,\"model_7\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c2d8bf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.69028871391076,\n",
       " 'precision': 0.7766466003315282,\n",
       " 'recall': 0.7769028871391076,\n",
       " 'f1': 0.7762334961702412}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7_results = calculate_results(val_labels,tf.round(model_7.predict(val_sentences)))\n",
    "model_7_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d2dbac",
   "metadata": {},
   "source": [
    "### Comparing the performance of each of our models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7c831c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fdeb2930",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_results = pd.DataFrame({\"baseline\":baseline_results,\n",
    "                                \"1_simple_dense\":model_1_results,\n",
    "                                \"2_lstm\":model_2_results,\n",
    "                                \"3_gru\":model_3_results,\n",
    "                                \"4_bidirectional\":model_4_results,\n",
    "                                \"5_conv1d\":model_5_results,\n",
    "                                \"6_tf_hub_use\":model_6_results,\n",
    "                                \"7_tf_hub_use_10_percent\":model_7_results})\n",
    "all_model_results = all_model_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "68506341",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "98140ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f5b52b664c0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "all_model_results.sort_values(\"f1\",ascending=False).plot(kind=\"bar\",figsize=(10,7)).legend(bbox_to_anchor=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5c96a3",
   "metadata": {},
   "source": [
    "### Uploading our model training logs to TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "769d93ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[0m\u001b[01;35m03-hamburger.jpeg\u001b[0m\r\n",
      " 03-hamburger.jpeg.1\r\n",
      " 03-hamburger.jpeg.2\r\n",
      " \u001b[01;35m03-pizza-dad.jpeg\u001b[0m\r\n",
      " 03-pizza-dad.jpeg.1\r\n",
      " 03-pizza-dad.jpeg.2\r\n",
      " 03-pizza-dad.jpeg.3\r\n",
      " \u001b[01;35m03-steak.jpeg\u001b[0m\r\n",
      " 03-steak.jpeg.1\r\n",
      " 03-steak.jpeg.2\r\n",
      " 03-steak.jpeg.3\r\n",
      " 03-steak.jpeg.4\r\n",
      " 03-steak.jpeg.5\r\n",
      " 03-steak.jpeg.6\r\n",
      " 03-steak.jpeg.7\r\n",
      " \u001b[01;35m03-sushi.jpeg\u001b[0m\r\n",
      " 03-sushi.jpeg.1\r\n",
      " 03-sushi.jpeg.2\r\n",
      " \u001b[01;34m06_101_food_class_10_percent_saved_big_dog_model\u001b[0m/\r\n",
      " \u001b[01;31m06_101_food_class_10_percent_saved_big_dog_model.zip\u001b[0m\r\n",
      " \u001b[01;31m08_model_6_USE_feature_extractor.zip\u001b[0m\r\n",
      " 101_classes_10_percent_data_model_checkpoint.data-00000-of-00001\r\n",
      " 101_classes_10_percent_data_model_checkpoint.index\r\n",
      " \u001b[01;34m101_food_classes_10_percent\u001b[0m/\r\n",
      " \u001b[01;31m101_food_classes_10_percent.zip\u001b[0m\r\n",
      " 101_food_classes_10_percent.zip.1\r\n",
      " \u001b[01;34m10_food_classes_10_percent\u001b[0m/\r\n",
      " \u001b[01;31m10_food_classes_10_percent.zip\u001b[0m\r\n",
      " \u001b[01;34m10_food_classes_1_percent\u001b[0m/\r\n",
      " \u001b[01;31m10_food_classes_1_percent.zip\u001b[0m\r\n",
      " \u001b[01;34m10_food_classes_all_data\u001b[0m/\r\n",
      " \u001b[01;31m10_food_classes_all_data.zip\u001b[0m\r\n",
      " \u001b[01;34m10_percent_model_checkpoints\u001b[0m/\r\n",
      " \u001b[01;34massets\u001b[0m/\r\n",
      " \u001b[01;34mbest_model_HDF5_format\u001b[0m/\r\n",
      " \u001b[01;34mbest_model_SavedModel_format\u001b[0m/\r\n",
      " checkpoint\r\n",
      " \u001b[01;34mcustom_food_images\u001b[0m/\r\n",
      " \u001b[01;31mcustom_food_images.zip\u001b[0m\r\n",
      " \u001b[01;34mel_modelo_del_acabe\u001b[0m/\r\n",
      " \u001b[01;34mfeature_extraction\u001b[0m/\r\n",
      "\u001b[01;31m'feature_extraction .zip'\u001b[0m\r\n",
      " \u001b[01;31mfeature_extraction.zip\u001b[0m\r\n",
      " helper_functions.py\r\n",
      " helper_functions.py.1\r\n",
      " \u001b[01;35mhow-to-cook-steak-1061w.jpg\u001b[0m\r\n",
      " how-to-cook-steak-1061w.jpg.1\r\n",
      " how-to-cook-steak-1061w.jpg.2\r\n",
      " how-to-cook-steak-1061w.jpg.3\r\n",
      " keras_metadata.pb\r\n",
      " \u001b[01;34m__MACOSX\u001b[0m/\r\n",
      " metadata.tsv\r\n",
      " \u001b[01;34mmodel_logs\u001b[0m/\r\n",
      " \u001b[01;35mmodel.png\u001b[0m\r\n",
      " \u001b[01;31mnlp_getting_started.zip\u001b[0m\r\n",
      " \u001b[01;34mpizza_steak\u001b[0m/\r\n",
      " \u001b[01;31mpizza_steak.zip\u001b[0m\r\n",
      " \u001b[01;34mprueba\u001b[0m/\r\n",
      " \u001b[01;34m__pycache__\u001b[0m/\r\n",
      " \u001b[01;34mrosalia_kim\u001b[0m/\r\n",
      " sample_submission.csv\r\n",
      " saved_model.pb\r\n",
      " Tensorflow00.ipynb\r\n",
      " Tensorflow01.ipynb\r\n",
      " Tensorflow02.ipynb\r\n",
      " Tensorflow03.ipynb\r\n",
      " Tensorflow04.ipynb\r\n",
      " Tensorflow05.ipynb\r\n",
      " Tensorflow_06.ipynb\r\n",
      " Tensorflow_08.ipynb\r\n",
      " test.csv\r\n",
      " train.csv\r\n",
      " \u001b[01;34mtranfer_learning\u001b[0m/\r\n",
      " \u001b[01;34mtransfer_learning\u001b[0m/\r\n",
      " Untitled.ipynb\r\n",
      " \u001b[01;34mvariables\u001b[0m/\r\n",
      " vectors.tsv\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0c2381eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "667ee92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 135396), started 0:02:18 ago. (Use '!kill 135396' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3598ac2561bf84d7\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3598ac2561bf84d7\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./model_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb916c71",
   "metadata": {},
   "source": [
    "### Save and load the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6e34b4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6.save(\"best_model.h5\")\n",
    "#h5 no lo guarda todo, el otro formato, sin nada, es el SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8eac1500",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_6 = tf.keras.models.load_model(\"best_model.h5\",\n",
    "                                               custom_objects ={\"KerasLayer\":hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "060423ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 2s 41ms/step - loss: 0.4256 - accuracy: 0.8215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42562517523765564, 0.8215222954750061]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model_6.evaluate(val_sentences,val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82946dcb",
   "metadata": {},
   "source": [
    "### Finding most wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "23899bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe with all the validation wrong dl\n",
    "model_pred_probs = loaded_model_6.predict(val_sentences)\n",
    "model_preds = tf.squeeze(tf.round(model_pred_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "eafd0047",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.DataFrame({\n",
    "    \"text\":val_sentences,\n",
    "    \"target\":val_labels,\n",
    "    \"pred\":model_preds,\n",
    "    \"probs\":model_pred_probs.reshape(-1,),\n",
    "    \"diff\": abs(val_df[\"target\"] - val_df[\"probs\"])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1828bcd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>probs</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ron &amp;amp; Fez - Dave's High School Crush https...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036125</td>\n",
       "      <td>0.963875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Reddit Will Now QuarantineÛ_ http://t.co/pkUA...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038457</td>\n",
       "      <td>0.961543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Why are you deluged with low self-image? Take ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045835</td>\n",
       "      <td>0.954165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>@SoonerMagic_ I mean I'm a fan but I don't nee...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047786</td>\n",
       "      <td>0.952214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>I get to smoke my shit in peace</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051207</td>\n",
       "      <td>0.948793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>@nagel_ashley @Vicken52 @BasedLaRock @goonc1ty...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.515176</td>\n",
       "      <td>0.515176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Back from Seattle Tacoma and Portland. Whirlwi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486793</td>\n",
       "      <td>0.513207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>@fewmoretweets all lives matter. Just not a fa...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.490495</td>\n",
       "      <td>0.509505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>@LegacyOfTheSith @SagaciousSaber @Lordofbetray...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.508845</td>\n",
       "      <td>0.508845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Medieval airplane hijacker testa: earnings the...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.496646</td>\n",
       "      <td>0.503354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  target  pred  \\\n",
       "23   Ron &amp; Fez - Dave's High School Crush https...       1   0.0   \n",
       "244  Reddit Will Now QuarantineÛ_ http://t.co/pkUA...       1   0.0   \n",
       "38   Why are you deluged with low self-image? Take ...       1   0.0   \n",
       "411  @SoonerMagic_ I mean I'm a fan but I don't nee...       1   0.0   \n",
       "233                    I get to smoke my shit in peace       1   0.0   \n",
       "..                                                 ...     ...   ...   \n",
       "384  @nagel_ashley @Vicken52 @BasedLaRock @goonc1ty...       0   1.0   \n",
       "69   Back from Seattle Tacoma and Portland. Whirlwi...       1   0.0   \n",
       "363  @fewmoretweets all lives matter. Just not a fa...       1   0.0   \n",
       "299  @LegacyOfTheSith @SagaciousSaber @Lordofbetray...       0   1.0   \n",
       "30   Medieval airplane hijacker testa: earnings the...       1   0.0   \n",
       "\n",
       "        probs      diff  \n",
       "23   0.036125  0.963875  \n",
       "244  0.038457  0.961543  \n",
       "38   0.045835  0.954165  \n",
       "411  0.047786  0.952214  \n",
       "233  0.051207  0.948793  \n",
       "..        ...       ...  \n",
       "384  0.515176  0.515176  \n",
       "69   0.486793  0.513207  \n",
       "363  0.490495  0.509505  \n",
       "299  0.508845  0.508845  \n",
       "30   0.496646  0.503354  \n",
       "\n",
       "[136 rows x 5 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df_wrong = val_df[val_df[\"target\"]!=val_df[\"pred\"]].sort_values(\"diff\",ascending=False)\n",
    "val_df_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "af38fa48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1, Pred: 0.0, Prob 0.4597623348236084 : \n",
      "    Text:Tension In Bayelsa As Patience Jonathan Plans To Hijack APC PDP http://t.co/epABiNcZmJ http://t.co/1SgzGtgfw9\n",
      "-------------------\n",
      "Target: 1, Pred: 0.0, Prob 0.4698718190193176 : \n",
      "    Text:China's Stock Market Crash: Are There Gems In The Rubble? http://t.co/BqBLWiw08g #ROIMentor #yycwalks\n",
      "-------------------\n",
      "Target: 1, Pred: 0.0, Prob 0.47205960750579834 : \n",
      "    Text:US wont upgrade its infrastructure? http://t.co/NGEHhG9YGa' it a bad situation and its going to get ugly very quickly #USA #sustainability\n",
      "-------------------\n",
      "Target: 0, Pred: 1.0, Prob 0.5252780318260193 : \n",
      "    Text:Emergency Response and Hazardous Chemical Management: Principles and Practices http://t.co/4sSuyhkgRB http://t.co/TDerBtgZ2k\n",
      "-------------------\n",
      "Target: 0, Pred: 1.0, Prob 0.5169254541397095 : \n",
      "    Text:What Natural Disaster Are You When You Get Angry? http://t.co/O9DzgZqEMf\n",
      "-------------------\n",
      "Target: 0, Pred: 1.0, Prob 0.5151762366294861 : \n",
      "    Text:@nagel_ashley @Vicken52 @BasedLaRock @goonc1ty rip the world... its burning\n",
      "-------------------\n",
      "Target: 1, Pred: 0.0, Prob 0.4867933690547943 : \n",
      "    Text:Back from Seattle Tacoma and Portland. Whirlwind! http://t.co/qwHINBni8e\n",
      "-------------------\n",
      "Target: 1, Pred: 0.0, Prob 0.4904954433441162 : \n",
      "    Text:@fewmoretweets all lives matter. Just not a fan of burning down buildings and stealing from your neighbors to 'protest'\n",
      "-------------------\n",
      "Target: 0, Pred: 1.0, Prob 0.5088447332382202 : \n",
      "    Text:@LegacyOfTheSith @SagaciousSaber @Lordofbetrayal Moved in a crescent formation small trails of dust left in their wake as they moved.\n",
      "-------------------\n",
      "Target: 1, Pred: 0.0, Prob 0.49664562940597534 : \n",
      "    Text:Medieval airplane hijacker testa: earnings the distinction divers: HtaRvrGLY\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "rd_index = rd.randint(len())\n",
    "for row in val_df_wrong[rd_index:rd_index+10].itertuples():\n",
    "    _,text,target,pred,prob,_ = row\n",
    "    print(f\"Target: {target}, Pred: {pred}, Prob {prob} : \\n\\\n",
    "    Text:{text}\")\n",
    "    print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46d4458",
   "metadata": {},
   "source": [
    "### Make predictions on the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c8f1cd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = test_df[\"text\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "fef3af1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 1s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "label_prob = loaded_model_6.predict(test_sentences)\n",
    "labels = tf.round(label_prob).numpy().reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "40b2e778",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"predicted_label\"] = labels\n",
    "test_df[\"predicted_prob\"] = label_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e1a0860d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: 1.0, Prob 0.724 : \n",
      "    Text:M9A1 PHROBIS III GREEN BAYONET MILITARY COMBAT SHEATH KNIFE NR http://t.co/dKxe44M8v9 http://t.co/A4PfB5Lt17\n",
      "-------------------\n",
      "Pred: 1.0, Prob 0.579 : \n",
      "    Text:@GorillaThumbz @FoxNews @jonathanserrie 'For sale Canadian military rifle dropped once'\n",
      "-------------------\n",
      "Pred: 0.0, Prob 0.129 : \n",
      "    Text:@AlexxPage cried at the mudslide cake ??\n",
      "-------------------\n",
      "Pred: 1.0, Prob 0.760 : \n",
      "    Text:#Tajikistan #Mudslides #China aids to #Mudslide-hit #Tajiks http://t.co/BD546mtcpN\n",
      "-------------------\n",
      "Pred: 0.0, Prob 0.279 : \n",
      "    Text:The one with the chocolate mudslide  #BakeOffFriends @BritishBakeOff @BBCOne #GBBO\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "rd_index = random.randint(0,len(test_df)-5)\n",
    "for row in test_df[rd_index:rd_index+5].itertuples():\n",
    "    _,_,_,_,text,label,label_prob = row\n",
    "    print(f\"Pred: {label}, Prob {label_prob:.3f} : \\n\\\n",
    "    Text:{text}\")\n",
    "    print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "cdc8c61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_prediction(phrase,model):\n",
    "    return model.predict([phrase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "b13ea5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.04991131]], dtype=float32)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase = \"Hello world\"\n",
    "custom_prediction(phrase,loaded_model_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0345616b",
   "metadata": {},
   "source": [
    "### Timer for predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "59ef0b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "def pred_timer(model,samples):\n",
    "    \"\"\"\n",
    "    Timer for hw long a model takes to make predicitons on samples     \n",
    "\"\"\"\n",
    "    start_time = time.perf_counter()\n",
    "    model.predict(samples)\n",
    "    end_time = time.perf_counter()\n",
    "    total_time = end_time - start_time\n",
    "    timer_per_pred = total_time/len(samples)\n",
    "    return total_time,timer_per_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "70891abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.21681954499217682, 0.00028454008529157064)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6_total_pred_time, model_6_time_per_pred = pred_timer(\n",
    "model = loaded_model_6,\n",
    "    samples=val_sentences\n",
    ")\n",
    "model_6_total_pred_time,model_6_time_per_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "15836e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07508889099699445, 9.854185170209246e-05)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_total_pred_time, baseline_time_per_pred = pred_timer(\n",
    "model = model_0,\n",
    "    samples=val_sentences\n",
    ")\n",
    "baseline_total_pred_time,baseline_time_per_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "f6a37269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f5bcb71e9a0>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(baseline_time_per_pred,baseline_results[\"f1\"],label=\"baseline\")\n",
    "plt.scatter(model_6_time_per_pred,model_6_results[\"f1\"],label=\"model_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20dd79b",
   "metadata": {},
   "source": [
    "### Extra curriculum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "96669df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "42372238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 4s 14ms/step - loss: 0.1867 - accuracy: 0.9508 - val_loss: 0.7035 - val_accuracy: 0.7703\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0687 - accuracy: 0.9755 - val_loss: 0.8155 - val_accuracy: 0.7664\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0513 - accuracy: 0.9797 - val_loss: 0.9184 - val_accuracy: 0.7690\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0438 - accuracy: 0.9813 - val_loss: 0.9758 - val_accuracy: 0.7664\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0405 - accuracy: 0.9807 - val_loss: 1.0157 - val_accuracy: 0.7664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5ad8128af0>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_sequential = tf.keras.Sequential([\n",
    "    layers.InputLayer(input_shape=(1,),dtype=tf.string),\n",
    "    text_vectorizer,\n",
    "    embedding,\n",
    "    layers.GlobalMaxPool1D(),\n",
    "    layers.Dense(64,activation=\"relu\"),\n",
    "    layers.Dense(1,activation=\"sigmoid\")\n",
    "])\n",
    "model_1_sequential.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=[\"accuracy\"])\n",
    "model_1_sequential.fit(x=train_sentences,\n",
    "                      y=train_labels,\n",
    "                      epochs=5,\n",
    "                      validation_data=(val_sentences,val_labels),\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "254813fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 15, 64)            49408     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,366,657\n",
      "Trainable params: 1,366,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "cdd7a08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 8s 26ms/step - loss: 0.1201 - accuracy: 0.9602 - val_loss: 1.0310 - val_accuracy: 0.7467\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0518 - accuracy: 0.9769 - val_loss: 1.5115 - val_accuracy: 0.7625\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 5s 24ms/step - loss: 0.0400 - accuracy: 0.9801 - val_loss: 1.4232 - val_accuracy: 0.7756\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0428 - accuracy: 0.9804 - val_loss: 1.3672 - val_accuracy: 0.7730\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0410 - accuracy: 0.9806 - val_loss: 1.7401 - val_accuracy: 0.7559\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5bcb867880>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_sequential = tf.keras.Sequential([\n",
    "    layers.InputLayer(input_shape=(1,),dtype=tf.string),\n",
    "    text_vectorizer,\n",
    "    embedding,\n",
    "    layers.LSTM(64,return_sequences=True),\n",
    "    layers.LSTM(64),\n",
    "    layers.Dense(64,activation=\"relu\"),\n",
    "    layers.Dense(1,activation=\"sigmoid\")\n",
    "])\n",
    "model_2_sequential.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=[\"accuracy\"])\n",
    "model_2_sequential.fit(x=train_sentences,\n",
    "                      y=train_labels,\n",
    "                      epochs=5,\n",
    "                      validation_data=(val_sentences,val_labels),\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "0dced487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 11, 64)            41024     \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Glo  (None, 64)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,325,249\n",
      "Trainable params: 1,325,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "97907652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.1130 - accuracy: 0.9596 - val_loss: 0.8879 - val_accuracy: 0.7402\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0487 - accuracy: 0.9780 - val_loss: 1.1022 - val_accuracy: 0.7572\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0368 - accuracy: 0.9819 - val_loss: 1.3385 - val_accuracy: 0.7520\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0318 - accuracy: 0.9829 - val_loss: 1.5304 - val_accuracy: 0.7493\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0301 - accuracy: 0.9850 - val_loss: 1.6287 - val_accuracy: 0.7480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5baf70f100>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_sequential = tf.keras.Sequential([\n",
    "    layers.InputLayer(input_shape=(1,),dtype=tf.string),\n",
    "    text_vectorizer,\n",
    "    embedding,\n",
    "    layers.Conv1D(filters=64,kernel_size=4),\n",
    "    layers.GlobalMaxPool1D(),\n",
    "    layers.Dense(64,activation=\"relu\"),\n",
    "    layers.Dense(1,activation=\"sigmoid\")\n",
    "])\n",
    "model_5_sequential.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=[\"accuracy\"])\n",
    "model_5_sequential.fit(x=train_sentences,\n",
    "                      y=train_labels,\n",
    "                      epochs=5,\n",
    "                      validation_data=(val_sentences,val_labels),\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "45bf1d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7217847769028871"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.fit(train_sentences_10_percent,train_label_10_percent)\n",
    "model_0.score(val_sentences,val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "b42f2fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a keras layer using the pretrained layer\n",
    "sentence_encoder_layer_ft = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                       input_shape= [],\n",
    "                                       dtype = tf.string,\n",
    "                                       trainable=True,\n",
    "                                       name=\"USE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "af44f102",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = tf.keras.Sequential([\n",
    "    sentence_encoder_layer,\n",
    "    layers.Dense(64,activation=\"relu\"),\n",
    "    layers.Dense(1,activation=\"sigmoid\",name=\"output_layer\")\n",
    "],name=\"model_ft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "92615d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "2b692cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs /model_ft/20220627-143619\n",
      "Epoch 1/10\n",
      "215/215 [==============================] - 3s 8ms/step - loss: 0.5055 - accuracy: 0.7822 - val_loss: 0.4494 - val_accuracy: 0.8005\n",
      "Epoch 2/10\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.4144 - accuracy: 0.8173 - val_loss: 0.4398 - val_accuracy: 0.8045\n",
      "Epoch 3/10\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.4014 - accuracy: 0.8221 - val_loss: 0.4363 - val_accuracy: 0.8136\n",
      "Epoch 4/10\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.3930 - accuracy: 0.8279 - val_loss: 0.4315 - val_accuracy: 0.8123\n",
      "Epoch 5/10\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.3879 - accuracy: 0.8300 - val_loss: 0.4293 - val_accuracy: 0.8150\n",
      "Epoch 6/10\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.3795 - accuracy: 0.8321 - val_loss: 0.4300 - val_accuracy: 0.8123\n",
      "Epoch 7/10\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.3741 - accuracy: 0.8352 - val_loss: 0.4257 - val_accuracy: 0.8163\n",
      "Epoch 8/10\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.3679 - accuracy: 0.8358 - val_loss: 0.4266 - val_accuracy: 0.8163\n",
      "Epoch 9/10\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.3624 - accuracy: 0.8415 - val_loss: 0.4280 - val_accuracy: 0.8150\n",
      "Epoch 10/10\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.3569 - accuracy: 0.8425 - val_loss: 0.4251 - val_accuracy: 0.8176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5af10b2e20>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.fit(x=train_sentences,\n",
    "            y=train_labels,\n",
    "            epochs=10,\n",
    "            validation_data=(val_sentences,val_labels),\n",
    "            callbacks=[create_tensorboard_callback(SAVE_DIR,\"model_ft\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247b199b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
