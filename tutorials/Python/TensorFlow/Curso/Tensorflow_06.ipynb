{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6390d59",
   "metadata": {},
   "source": [
    "## Transfer learning : Scaling up \n",
    "\n",
    "The point is to use transfer learning and extrapolate to the 101 food classes in the original dataset, trying to beat the accuracy of the original paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d00c90c",
   "metadata": {},
   "source": [
    "At this point, i should use a GPU. GG WPPPPP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29595e25",
   "metadata": {},
   "source": [
    "## Creating helper functions \n",
    "\n",
    "In previous notebooks, helper functions have been created. Let's use them !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c689a185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-06-13 15:37:14--  https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/helper_functions.py\n",
      "Resolvendo github.com (github.com)... 140.82.121.3\n",
      "Conectando con github.com (github.com)|140.82.121.3|:443... conectado.\n",
      "Petición HTTP enviada, agardando unha resposta... 200 OK\n",
      "Lonxitude: sen especificar [text/html]\n",
      "Gardando en: «helper_functions.py.1»\n",
      "\n",
      "helper_functions.py     [  <=>               ] 246,99K  1,13MB/s    in 0,2s    \n",
      "\n",
      "2022-06-13 15:37:15 (1,13 MB/s) - gardouse «helper_functions.py.1» [252916]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/helper_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bedb1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-13 15:37:15.474431: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-13 15:37:15.474457: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Import helper functions in our notebook\n",
    "from helper_functions import create_tensorboard_callback,plot_loss_curves,unzip_data,compare_historys,walk_through_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686ccf1b",
   "metadata": {},
   "source": [
    "## 101 Food Classes: working with less data\n",
    "\n",
    "The goal is beat the state of the art, with less data, download it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9fb054e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-06-13 15:37:18--  https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip\n",
      "Resolvendo storage.googleapis.com (storage.googleapis.com)... 142.250.201.80, 142.250.200.112, 216.58.215.176, ...\n",
      "Conectando con storage.googleapis.com (storage.googleapis.com)|142.250.201.80|:443... conectado.\n",
      "Petición HTTP enviada, agardando unha resposta... 200 OK\n",
      "Lonxitude: 1625420029 (1,5G) [application/zip]\n",
      "Gardando en: «101_food_classes_10_percent.zip.1»\n",
      "\n",
      "s_10_percent.zip.1    2%[                    ]  40,48M  8,54MB/s    eta 3m 9s  ^C\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwget https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43munzip_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m101_food_classes_10_percent.zip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Python/TensorFlow/Curso/helper_functions.py:244\u001b[0m, in \u001b[0;36munzip_data\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munzip_data\u001b[39m(filename):\n\u001b[1;32m    238\u001b[0m   \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m  Unzips filename into the current working directory.\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \n\u001b[1;32m    241\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;124;03m    filename (str): a filepath to a target zip folder to be unzipped.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m   zip_ref \u001b[38;5;241m=\u001b[39m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m   zip_ref\u001b[38;5;241m.\u001b[39mextractall()\n\u001b[1;32m    246\u001b[0m   zip_ref\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.8/zipfile.py:1269\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1267\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 1269\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1271\u001b[0m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[1;32m   1272\u001b[0m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[1;32m   1273\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_didModify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/zipfile.py:1332\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1330\u001b[0m fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1332\u001b[0m     endrec \u001b[38;5;241m=\u001b[39m \u001b[43m_EndRecData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1334\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.8/zipfile.py:274\u001b[0m, in \u001b[0;36m_EndRecData\u001b[0;34m(fpin)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 274\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mfpin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m sizeEndCentDir \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    276\u001b[0m     data[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m==\u001b[39m stringEndArchive \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    277\u001b[0m     data[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\000\u001b[39;00m\u001b[38;5;130;01m\\000\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;66;03m# the signature is correct and there's no comment, unpack structure\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     endrec \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(structEndArchive, data)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip\n",
    "unzip_data(\"101_food_classes_10_percent.zip\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aebb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_through_dir(\"101_food_classes_10_percent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de440c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup data inputs\n",
    "import tensorflow as tf\n",
    "\n",
    "train_dir = \"101_food_classes_10_percent/train\"\n",
    "test_dir = \"101_food_classes_10_percent/test\"\n",
    "\n",
    "IMG_SIZE = (224,224)\n",
    "train_data_all_10_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
    "                                                                                label_mode=\"categorical\",\n",
    "                                                                                image_size=IMG_SIZE)\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
    "                                                               label_mode=\"categorical\",\n",
    "                                                               image_size=IMG_SIZE,\n",
    "                                                               shuffle=False)\n",
    "#Dont shuffle test data for prediction analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317748b8",
   "metadata": {},
   "source": [
    "## Train a big dog model with TF on 10% of 1010 Food classes \n",
    "\n",
    "Here are the steps we're going to take: \n",
    "* Create a ModelCheckpoint callback\n",
    "* Create a data augmentation layer\n",
    "* Build a headless(no top layers) functional efficientnetb0 backbone model\n",
    "* Compile our model \n",
    "* Feature extract for 5 epochs and validate on 15% of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d9c451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoint callback\n",
    "checkpoint_path = \"101_classes_10_percent_data_model_checkpoint\"\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                        save_weights_only=True,\n",
    "                                                        monitor=\"val_accuracy\",\n",
    "                                                        save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf100584",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a data augmentation layer to incorporate to the model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "#Setup data augmentation\n",
    "data_augmentation = Sequential([\n",
    "    preprocessing.RandomFlip(\"horizontal\"),\n",
    "    preprocessing.RandomRotation(0.2),\n",
    "    preprocessing.RandomHeight(0.2),\n",
    "    preprocessing.RandomWidth(0.2),\n",
    "    preprocessing.RandomZoom(0.2),\n",
    "    #preprocessing.Rescaling(1/255.) #Necessary for Resnet\n",
    "],name=\"data_augmentation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b9dcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the base model and freeze its layers(this will extract features)\n",
    "\n",
    "base_model =tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "# Setup model atchitecture with trainable top layers\n",
    "\n",
    "inputs = layers.Input(shape=(224,224,3),name = \"input_layer\")\n",
    "x = data_augmentation(inputs)#only in training\n",
    "x = base_model(x,training=False) # to keep it frozen\n",
    "x = layers.GlobalAveragePooling2D(name=\"global_avg_pool_layer\")(x)\n",
    "outputs = layers.Dense(len(train_data_all_10_percent.class_names),activation=\"softmax\",name=\"output\")(x)\n",
    "model = tf.keras.Model(inputs,outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dc37f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd3e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "             metrics = [\"accuracy\"])\n",
    "\n",
    "history_all_classes_10_percent = model.fit(train_data_all_10_percent,\n",
    "                                          epochs=5,\n",
    "                                           validation_data=test_data,\n",
    "                                          validation_steps=int(0.15*len(test_data)),\n",
    "                                          callbacks = [checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae6bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate\n",
    "feature_extraction_results = model.evaluate(test_data)\n",
    "feature_extraction_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3974d230",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(history_all_classes_10_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679c630e",
   "metadata": {},
   "source": [
    "## Fine tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9ce91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze all of the layers in the base model \n",
    "base_model.trainable = True\n",
    "\n",
    "#Refreeze except 5 last \n",
    "for layer in base_model.layers[:-5]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d2d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recompile  and lower learning rate (good practise with fine tuning)\n",
    "model.compile(loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "             optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "             metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4222be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What layers are trainbable :\n",
    "for layer in model.layers:\n",
    "    print(layer.name,layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845b66de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_number,layer in enumerate(base_model.layers):\n",
    "    print(layer_number,layer.name,layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757dadc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine- tune for more 5 epochs \n",
    "fine_tune_epochs = 10 \n",
    "\n",
    "history_all_classes_10_percent_fine_tune = model.fit(train_data_all_10_percent,\n",
    "                                                    epochs = fine_tune_epochs,\n",
    "                                                    validation_data=test_data,\n",
    "                                                    validation_steps=int(0.15*len(test_data)),\n",
    "                                                    initial_epoch = history_all_classes_10_percent.epoch[-1]\n",
    "                                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889e8d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate\n",
    "all_classes_10_percent_fine_tune_results = model.evaluate(test_data)\n",
    "all_classes_10_percent_fine_tune_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5707dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_historys(history_all_classes_10_percent,history_all_classes_10_percent_fine_tune)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987cb23f",
   "metadata": {},
   "source": [
    "## Saving and loading our model \n",
    "\n",
    "To use it in an external app, need no export it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69833d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Save fine-tuning model \n",
    "model.save(filepath = os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5926a16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an evaluate saved model \n",
    "import os\n",
    "loaded_model = tf.keras.models.load_model(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baebd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate loaded model and compare performance to pre-saved model\n",
    "loaded_model_results = loaded_model.evaluate(test_data)\n",
    "loaded_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27030a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classes_10_percent_fine_tune_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292f9d4b",
   "metadata": {},
   "source": [
    "### Evaluate the model on predictions\n",
    "\n",
    "Make predictions, visualize them and check the most wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c188f742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#Download pretrained model to compare with bosses\n",
    "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/06_101_food_class_10_percent_saved_big_dog_model.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06138c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "unzip_data(\"06_101_food_class_10_percent_saved_big_dog_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2920a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"06_101_food_class_10_percent_saved_big_dog_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d33070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate loaded model on test data\n",
    "results_downloaded_model = model.evaluate(test_data)\n",
    "results_downloaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e281d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f0a4cc",
   "metadata": {},
   "source": [
    "## Make predictions with trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a94d349",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_probs = model.predict(test_data, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2abf997",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred classes for each label \n",
    "pred_classes = preds_probs.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a7b173",
   "metadata": {},
   "source": [
    "The model outputs a prediction probability for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff5cc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get out test labels we need to unravel our test_data\n",
    "y_labels = []\n",
    "for images,labels in test_data.unbatch():\n",
    "    y_labels.append(labels.numpy().argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48222b8",
   "metadata": {},
   "source": [
    "We have to chech if our model predictions array is in the same order as this one. One way to do this is measure the accuracy score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5989db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de86099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_accuracy = accuracy_score(y_labels,pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ca8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.isclose(sklearn_accuracy,all_classes_10_percent_fine_tune_results,10e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5164e3",
   "metadata": {},
   "source": [
    "### Confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6305decd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import create_tensorboard_callback,plot_loss_curves,unzip_data,compare_historys,walk_through_dir\n",
    "from helper_functions import make_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b25781",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_confusion_matrix(y_labels,pred_classes,test_data.class_names,\n",
    "                     figsize=(100,100),\n",
    "                     text_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66c05aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## New metric evaluations, this time, a classification report from sklearn \n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af87ca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_labels,y_pred=pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ad8fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a dictionary of the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a6813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report_dict = classification_report(y_true=y_labels,y_pred=pred_classes,output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190f7339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot of F1-scores\n",
    "class_f1_scores = {}\n",
    "for k,v in classification_report_dict.items():\n",
    "    if k == \"accuracy\":\n",
    "        break\n",
    "    else:\n",
    "        class_f1_scores[test_data.class_names[int(k)]] = v[\"f1-score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b3b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe\n",
    "import pandas as pd\n",
    "f1_scores = pd.DataFrame({\"class_names\": list(class_f1_scores.keys()),\n",
    "                         \"f1-score\":list(class_f1_scores.values())}\n",
    "                        ).sort_values(by=\"f1-score\")\n",
    "f1_scores.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913c2c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots(figsize=(12,25))\n",
    "scores = ax.barh(range(len(f1_scores)),f1_scores[\"f1-score\"].values)\n",
    "ax.set_yticks(range(len(f1_scores)))\n",
    "ax.set_yticklabels(f1_scores[\"class_names\"]);\n",
    "ax.set_title(\"F1-scores for 101 foods \");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cb285a",
   "metadata": {},
   "source": [
    "## Visualizing predictions on test images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6318c7f9",
   "metadata": {},
   "source": [
    "To visualize our model predictions on our own images, we need a function to load and preprocess images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8c21ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create that function \n",
    "def load_and_prep_image(filename,img_shape=224,scale=True):\n",
    "    \"\"\"Reads in an image from filenae, turns into a tensor and \n",
    "    reshapes into specified shape.\n",
    "    \"\"\"\n",
    "    #Read\n",
    "    img = tf.io.read_file(filename)\n",
    "    #Convert to tensor\n",
    "    img = tf.io.decode_image(img,channels=3)\n",
    "    #Resize\n",
    "    img = tf.image.resize(img,[img_shape,img_shape])\n",
    "    \n",
    "    #Scale\n",
    "    if scale:\n",
    "        return img/255.0\n",
    "    else:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcd7519",
   "metadata": {},
   "source": [
    " Write the code to visualize images, target label and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ff7c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make preds on a series of random images\n",
    "import os \n",
    "import random \n",
    "\n",
    "plt.figure(figsize=(17,10))\n",
    "for i in range(3):\n",
    "    class_name = random.choice(test_data.class_names)\n",
    "    filename = random.choice(os.listdir(test_dir+\"/\"+class_name))\n",
    "    filepath = test_dir+ \"/\" + class_name + \"/\" + filename\n",
    "    #Load the image and make predictions\n",
    "    img = load_and_prep_image(filepath,scale=False)\n",
    "    pred_prob = model.predict(tf.expand_dims(img,axis=0))\n",
    "    pred_class = test_data.class_names[pred_prob.argmax()]\n",
    "    #Plot the image\n",
    "    plt.subplot(1,3,1+i)\n",
    "    plt.imshow(img/255.)\n",
    "    if class_name == pred_class:\n",
    "        title_color = \"g\"\n",
    "    else: \n",
    "        title_color = \"r\"\n",
    "    plt.title(f\"actual: {class_name}, pred: {pred_class}\",color=title_color)\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d0ece1",
   "metadata": {},
   "source": [
    "## Finding the most wrong predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02123fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = []\n",
    "for filepath in tf.data.Dataset.list_files(test_dir+\"/*/*.jpg\",shuffle=False):\n",
    "    filepaths.append(filepath.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021445c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe of different parameters for our test images\n",
    "import pandas as pd\n",
    "pred_df = pd.DataFrame({\"img_path\":filepaths,\n",
    "                        \"y_true\":y_labels,\n",
    "                        \"y_pred\":pred_classes,\n",
    "                        \"pred_conf\":preds_probs.max(axis=1),\n",
    "                        \"y_true_classname\":[test_data.class_names[i] for i in y_labels],\n",
    "                        \"y_pred_classname\":[test_data.class_names[i] for i in pred_classes]\n",
    "                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcae211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find out the most wrong predictions\n",
    "\n",
    "pred_df[\"pred_correct\"] = pred_df[\"y_true\"] == pred_df[\"y_pred\"]\n",
    "pred_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abea8511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort our dataframe to make the most wrong go up \n",
    "top_100_wrong = pred_df[pred_df[\"pred_correct\"] == False].sort_values(by=\"pred_conf\",ascending=False)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944df1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_wrong.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f94d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top_100_wrong\n",
    "images_to_view = 9 \n",
    "start_index = 30\n",
    "plt.figure(figsize=(15,10))\n",
    "for i,row in enumerate(top_100_wrong[start_index:start_index+images_to_view].itertuples()):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    img = load_and_prep_image(row[1],scale=False)\n",
    "    plt.imshow(img/255.)\n",
    "    plt.axis(False)\n",
    "    _,_,_,_,pred_prob,y_true_classname,y_pred_classname,_ = row\n",
    "    plt.title(f\"actual:{y_true_classname}, pred: {y_pred_classname},\\n prob {pred_prob:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fc693b",
   "metadata": {},
   "source": [
    "### Predict on custom images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03180037",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get custom images\n",
    "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/custom_food_images.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af12863",
   "metadata": {},
   "outputs": [],
   "source": [
    "unzip_data(\"custom_food_images.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1752525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_food_images = [\"custom_food_images/\"+img_path for img_path in os.listdir(\"custom_food_images/\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9591e2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions and plot custom food images\n",
    "for img in custom_food_images:\n",
    "    img = load_and_prep_image(img,scale=False)\n",
    "    pred_prob = model.predict(tf.expand_dims(img,axis=0))\n",
    "    pred_class = test_data.class_names[pred_prob.argmax()]\n",
    "    plt.figure()\n",
    "    plt.imshow(img/255.)\n",
    "    plt.title(f\"pred:{pred_class},prob:{pred_prob.max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3e1d64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
