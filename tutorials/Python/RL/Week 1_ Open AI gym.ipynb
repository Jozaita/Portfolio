{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73281515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5db1ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a71ace1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The observation space: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n",
      "The action space: Discrete(3)\n"
     ]
    }
   ],
   "source": [
    "# Observation and action space \n",
    "obs_space = env.observation_space\n",
    "action_space = env.action_space\n",
    "print(\"The observation space: {}\".format(obs_space))\n",
    "print(\"The action space: {}\".format(action_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abbf675b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial observation is [-0.47340074  0.        ]\n",
      "The new observation is [-0.47277582  0.00062494]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# reset the environment and see the initial observation\n",
    "obs = env.reset()\n",
    "print(\"The initial observation is {}\".format(obs))\n",
    "\n",
    "# Sample a random action from the entire action space\n",
    "random_action = env.action_space.sample()\n",
    "\n",
    "# # Take the action and get the new observation space\n",
    "new_obs, reward, done, info = env.step(random_action)\n",
    "print(\"The new observation is {}\".format(new_obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec7ff88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "# Number of steps you run the agent for \n",
    "num_steps = 150\n",
    "\n",
    "obs = env.reset()\n",
    "\n",
    "for step in range(num_steps):\n",
    "    # take random action, but you can also do something more intelligent\n",
    "    # action = my_intelligent_agent_fn(obs) \n",
    "    action = env.action_space.sample()\n",
    "    \n",
    "    # apply the action\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    \n",
    "    # Render the env\n",
    "    env.render()\n",
    "\n",
    "    # Wait a bit before the next frame unless you want to see a crazy fast video\n",
    "    time.sleep(0.001)\n",
    "    \n",
    "    # If the epsiode is up, then start another one\n",
    "    if done:\n",
    "        env.reset()\n",
    "\n",
    "# Close the env\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3deb737a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper Bound for Env Observation [0.6  0.07]\n",
      "Lower Bound for Env Observation [-1.2  -0.07]\n"
     ]
    }
   ],
   "source": [
    "print(\"Upper Bound for Env Observation\", env.observation_space.high)\n",
    "print(\"Lower Bound for Env Observation\", env.observation_space.low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b012dd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gym.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96c12e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.7.5+db37282)\n",
      "[Powered by Stella]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Space:  Box(0, 255, (210, 160, 3), uint8)\n",
      "Action Space        Discrete(4)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import gym\n",
    "env = gym.make(\"BreakoutNoFrameskip-v4\")\n",
    "\n",
    "print(\"Observation Space: \", env.observation_space)\n",
    "print(\"Action Space       \", env.action_space)\n",
    "\n",
    "\n",
    "obs = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    #env.render()\n",
    "    time.sleep(0.01)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11a372f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "\n",
    "class ConcatObs(gym.Wrapper):\n",
    "    def __init__(self, env, k):\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        self.k = k\n",
    "        self.frames = deque([], maxlen=k)\n",
    "        shp = env.observation_space.shape\n",
    "        self.observation_space = \\\n",
    "            spaces.Box(low=0, high=255, shape=((k,) + shp), dtype=env.observation_space.dtype)\n",
    "\n",
    "\n",
    "def reset(self):\n",
    "    ob = self.env.reset()\n",
    "    for _ in range(self.k):\n",
    "        self.frames.append(ob)\n",
    "    return self._get_ob()\n",
    "\n",
    "def step(self, action):\n",
    "    ob, reward, done, info = self.env.step(action)\n",
    "    self.frames.append(ob)\n",
    "    return self._get_ob(), reward, done, info\n",
    "\n",
    "def _get_ob(self):\n",
    "    return np.array(self.frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1c8db30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new observation space is Box(0, 255, (4, 210, 160, 3), uint8)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"BreakoutNoFrameskip-v4\")\n",
    "wrapped_env = ConcatObs(env, 4)\n",
    "print(\"The new observation space is\", wrapped_env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "901cdf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intial obs is of the shape (210, 160, 3)\n",
      "Obs after taking a step is (210, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "# Reset the Env\n",
    "obs = wrapped_env.reset()\n",
    "print(\"Intial obs is of the shape\", obs.shape)\n",
    "\n",
    "# Take one step\n",
    "obs, _, _, _  = wrapped_env.step(2)\n",
    "print(\"Obs after taking a step is\", obs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b06e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "class ObservationWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "    \n",
    "    def observation(self, obs):\n",
    "        # Normalise observation by 255\n",
    "        return obs / 255.0\n",
    "\n",
    "class RewardWrapper(gym.RewardWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "    \n",
    "    def reward(self, reward):\n",
    "        # Clip reward between 0 to 1\n",
    "        return np.clip(reward, 0, 1)\n",
    "    \n",
    "class ActionWrapper(gym.ActionWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "    \n",
    "    def action(self, action):\n",
    "        if action == 3:\n",
    "            return random.choice([0,1,2])\n",
    "        else:\n",
    "            return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10262cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All checks passed\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"BreakoutNoFrameskip-v4\",render_mode=\"human\")\n",
    "wrapped_env = ObservationWrapper(RewardWrapper(ActionWrapper(env)))\n",
    "\n",
    "obs = wrapped_env.reset()\n",
    "\n",
    "for step in range(500):\n",
    "    action = wrapped_env.action_space.sample()\n",
    "    obs, reward, done, info = wrapped_env.step(action)\n",
    "    \n",
    "    # Raise a flag if values have not been vectorised properly\n",
    "    if (obs > 1.0).any() or (obs < 0.0).any():\n",
    "        print(\"Max and min value of observations out of range\")\n",
    "    \n",
    "    # Raise a flag if reward has not been clipped.\n",
    "    if reward < 0.0 or reward > 1.0:\n",
    "        assert False, \"Reward out of bounds\"\n",
    "    \n",
    "    # Check the rendering if the slider moves to the left.\n",
    "    #wrapped_env.render()\n",
    "    \n",
    "    time.sleep(0.001)\n",
    "\n",
    "wrapped_env.close()\n",
    "\n",
    "print(\"All checks passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "217e8530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapped Env: <ObservationWrapper<RewardWrapper<ActionWrapper<TimeLimit<OrderEnforcing<AtariEnv<BreakoutNoFrameskip-v4>>>>>>>\n",
      "Unwrapped Env <AtariEnv<BreakoutNoFrameskip-v4>>\n",
      "Getting the meaning of actions ['NOOP', 'FIRE', 'RIGHT', 'LEFT']\n"
     ]
    }
   ],
   "source": [
    "print(\"Wrapped Env:\", wrapped_env)\n",
    "print(\"Unwrapped Env\", wrapped_env.unwrapped)\n",
    "print(\"Getting the meaning of actions\", wrapped_env.unwrapped.get_action_meanings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1313aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/.local/lib/python3.8/site-packages/baselines/common/vec_env/shmem_vec_env.py:17: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool: ctypes.c_bool}\n",
      "A.L.E: Arcade Learning Environment (version 0.7.5+db37282)\n",
      "[Powered by Stella]\n",
      "A.L.E: Arcade Learning Environment (version 0.7.5+db37282)\n",
      "[Powered by Stella]A.L.E: Arcade Learning Environment (version 0.7.5+db37282)\n",
      "[Powered by Stella]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the neccasary stuff \n",
    "import gym\n",
    "from baselines.common.vec_env.subproc_vec_env import SubprocVecEnv\n",
    "\n",
    "# list of envs \n",
    "num_envs = 3\n",
    "envs = [lambda: gym.make(\"BreakoutNoFrameskip-v4\") for i in range(num_envs)]\n",
    "\n",
    "# Vec Env \n",
    "envs = SubprocVecEnv(envs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7e8202b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.7.5+db37282)\n",
      "[Powered by Stella]A.L.E: Arcade Learning Environment (version 0.7.5+db37282)\n",
      "[Powered by Stella]\n",
      "\n",
      "A.L.E: Arcade Learning Environment (version 0.7.5+db37282)\n",
      "[Powered by Stella]\n",
      "/home/juan/.local/lib/python3.8/site-packages/baselines/common/vec_env/shmem_vec_env.py:17: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool: ctypes.c_bool}\n",
      "/home/juan/.local/lib/python3.8/site-packages/baselines/common/vec_env/shmem_vec_env.py:17: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool: ctypes.c_bool}\n",
      "/home/juan/.local/lib/python3.8/site-packages/baselines/common/vec_env/shmem_vec_env.py:17: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool: ctypes.c_bool}\n"
     ]
    }
   ],
   "source": [
    "# render the envs\n",
    "import time \n",
    "\n",
    "# list of envs \n",
    "num_envs = 3\n",
    "envs = [lambda: gym.make(\"BreakoutNoFrameskip-v4\",render_mode=\"human\") for i in range(num_envs)]\n",
    "\n",
    "# Vec Env \n",
    "envs = SubprocVecEnv(envs)\n",
    "\n",
    "init_obs = envs.reset()\n",
    "\n",
    "for i in range(1000):\n",
    "    actions = [envs.action_space.sample() for i in range(num_envs)]\n",
    "    envs.step(actions)\n",
    "    #envs.render()\n",
    "    time.sleep(0.001)\n",
    "\n",
    "envs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3bb3e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
