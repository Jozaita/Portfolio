{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ego networks \n",
    "\n",
    "In this notebook, we will build the ego networks using the two dataframes of clean data obtained in the past notebook _clean.ipynb_. In order to achieve this: \n",
    "\n",
    "* We will use the library _networkx_ to transform the dataframe of relationships between the alteri into the different ego networks. \n",
    "* We will extract some measures of the structure of this ego networks and create with them a dataframe, as our goal is to use them as predictors of the nationality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the .csv files \n",
    "\n",
    "We import the different libraries, the usual numpy, pandas, matplotlib and networkx. The methods library that can be seen contains the algorithms to calculate the Dunbar estructure of an individual given an ego network. We will also incorporate this measure in our analysis in order to provide a more complete view. Then we load our .csv files and delete the unformatted columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Import libraries\n",
    "from numpy import nan\n",
    "import pandas as pd \n",
    "import networkx as nx\n",
    "from methods import *\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "###Load .csv files\n",
    "contactos=pd.read_csv(r'/home/juan/Python/Acculturation/Contactos.csv',low_memory=False)\n",
    "df=pd.read_csv(r'/home/juan/Python/Acculturation/all_data_clean.csv',low_memory=False)\n",
    "\n",
    "###Delete useless columns\n",
    "del contactos['Unnamed: 0']\n",
    "del df['Unnamed: 0']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find out the total number of subjects\n",
    "\n",
    "In order to begin the calculations, we calculate the total number of subjets. We also transform the datatype of the columns that are going to play a role in the dessign of the ego networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of subjects is 473\n"
     ]
    }
   ],
   "source": [
    "###Change datatypes\n",
    "contactos['Alter']=contactos['Alter'].astype(int)\n",
    "contactos['Alter2']=contactos['Alter2'].astype(int)\n",
    "\n",
    "#Find out the total number of subjects \n",
    "sujetos = len(contactos['sub/num'].unique())\n",
    "print(\"The total number of subjects is {}\".format(sujetos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ego networks and measuring their properties \n",
    "\n",
    "At this point, we build the ego networks. Coming from the contacts dataframe, we build a _networkx_ graph and we go through all the subjects, one by one, introducing the ties between alteris as links between nodes. And the intensity of their relationships determines the weight associated with the link. \n",
    "<br> <br>\n",
    "Once we have these graphs, we compute different properties: _Average degree, betweenness, closeness, clustering, load centrality, size of the largest component, number of components.._ Apart from these structural measures, we also compute the average intensity with people from their origin country and people from their residence country and their presence (the total number in the ego network). We store all these values in different lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/anaconda3/lib/python3.7/site-packages/networkx/algorithms/assortativity/correlation.py:287: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return (xy * (M - ab)).sum() / numpy.sqrt(vara * varb)\n"
     ]
    }
   ],
   "source": [
    "###We create the list in order to store the ego networks and their different properties. \n",
    "graficas=[0]*sujetos\n",
    "avdeg=[0]*sujetos\n",
    "betw=[0]*sujetos\n",
    "closs=[0]*sujetos\n",
    "assort=[0]*sujetos\n",
    "clustering=[0]*sujetos\n",
    "load=[0]*sujetos\n",
    "size=[0]*sujetos\n",
    "comp=[0]*sujetos\n",
    "ori=[0]*sujetos\n",
    "num=[0]*sujetos\n",
    "res=[0]*sujetos\n",
    "closnac=[0]*sujetos\n",
    "closnonac=[0]*sujetos\n",
    "numnac=[0]*sujetos\n",
    "mu=[0]*sujetos\n",
    "numnonac=[0]*sujetos\n",
    "vect=[[0]*5 for i in range(sujetos)]\n",
    "\n",
    "###We compute these ego networks and their attributes\n",
    "\n",
    "for k,j in enumerate(contactos[\"sub/num\"].unique()):\n",
    "    graficas[k]=nx.Graph()\n",
    "    ###We select the data that corresponds to each subject\n",
    "    data=contactos[contactos['sub/num']==j]\n",
    "    if (len(data)>0):\n",
    "        ###We compute the different number of subjects and their intensity. \n",
    "        ###This will be used to calculate the Dunbar parameters. \n",
    "        datamu=df['Clos'][df['sub/num']==j].value_counts()\n",
    "        for m in range(0,len(datamu)):\n",
    "            vect[k][datamu.index[m]-1]= datamu[datamu.index[m]]\n",
    "        ###Building the ego networks\n",
    "        edges=list(zip(data['Alter'],data['Alter2'],data['Value']))\n",
    "        graficas[k].add_weighted_edges_from(edges,'Value')\n",
    "        ###Measuring the networks\n",
    "        degrees=[val for (node, val) in graficas[k].degree()]\n",
    "        avdeg[k]=sum(degrees)/len(degrees)\n",
    "        betw[k]=sum(nx.betweenness_centrality(graficas[k],weight='Value').values())/len(nx.betweenness_centrality(graficas[k]).values())\n",
    "        closs[k]=sum(nx.closeness_centrality(graficas[k]).values())/len(nx.closeness_centrality(graficas[k]).values())\n",
    "        load[k]=sum(nx.load_centrality(graficas[k],weight='Value').values())/len(nx.load_centrality(graficas[k]).values())\n",
    "        assort[k]=nx.degree_assortativity_coefficient(graficas[k],weight=\"Value\")\n",
    "        size[k]= len(max(nx.connected_components(graficas[k]), key=len))/len(graficas[k].nodes())\n",
    "        clustering[k]=nx.average_clustering(graficas[k],weight='Value')\n",
    "        \n",
    "        comp[k]=nx.number_connected_components(graficas[k])\n",
    "        ego_origin = df['sub/origin'][df['sub/num'] == j].unique()[0]\n",
    "        ego_residence = df['sub/residence'][df['sub/num'] == j].unique()[0]\n",
    "        closnac[k]=df['Clos'][(df['sub/num'] == j) & (df['alter/origin'] == ego_origin)].mean() \n",
    "        numnac[k]=df['Clos'][(df['sub/num'] == j) & (df['alter/origin'] == ego_origin)].count()\n",
    "        closnonac[k]=df['Clos'][(df['sub/num'] == j) & (df['alter/origin'] == ego_residence)].mean()\n",
    "        numnonac[k]=df['Clos'][(df['sub/num'] == j) & (df['alter/origin'] == ego_residence)].count()\n",
    "        ori[k]=ego_origin\n",
    "        num[k]=j\n",
    "        res[k]=ego_residence\n",
    "    else: print(j)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the ego networks dataframe \n",
    "\n",
    "Coming from the previous lists, we create the networks dataframe, that contains the ego networks and their attributes. At this point, we also compute the Dunbar's parameter $\\mu$ and add it to our dataframe, with its confidence interval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/anaconda3/lib/python3.7/site-packages/scipy/optimize/minpack.py:175: RuntimeWarning: The number of calls to function has reached maxfev = 400.\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "/home/juan/Python/Acculturation/methods.py:49: IntegrationWarning: Extremely bad integrand behavior occurs at some points of the\n",
      "  integration interval.\n",
      "  return integrate.quad(integrand_leg,args = (R,L,r), a=0., b=t)[0]\n",
      "/home/juan/anaconda3/lib/python3.7/site-packages/scipy/optimize/minpack.py:175: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "###Creation of the dataframe\n",
    "redes=pd.DataFrame(data={'Subject origin':ori,'Subject residence':res,'Subject ID':num,'Vect':vect,'Graphs':graficas,\n",
    "                         'Average degree':avdeg,'Betweenness':betw,'Closeness':closs,'Load centrality':load,\n",
    "                         'Assortativity':assort,'Clustering':clustering,\n",
    "                         'Number components':comp,'Size largest component':size,\n",
    "                         'Closeness residence':closnonac,'Closeness origin':closnac,'Number residence':numnonac,\n",
    "                         'Number origin':numnac})\n",
    "df.isnull().sum()\n",
    "redes.fillna(-2,inplace=True)\n",
    "###Calculating the Dunbar's parameters \n",
    "redes['Fitted']=redes['Vect'].apply(lambda x:Individual(x).fit_model())\n",
    "redes[['Mu','Mu-','Mu+']] = pd.DataFrame(redes.Fitted.values.tolist(), index= redes.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some changes in the dataframe \n",
    "\n",
    "At this point, we make some changes in the ego networks dataframe. We introduce a function that substitutes the confidence interval of the $\\mu$ by an string that determines the regime. Then we delete the columns associated with the confidence interval, fill the _NaN_ and rename some columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Creating function to make clearer the regime\n",
    "def rex(x,y):\n",
    "    if ((x < 0) & (y < 0)): z='Inverted'\n",
    "    elif ((x > 0) & (y > 0)): z='Standard'\n",
    "    else : z='Unclear'\n",
    "    return z\n",
    "\n",
    "###Introducing the former function in our dataframe\n",
    "regime=[0]*sujetos\n",
    "for i in range(len(redes)):\n",
    "    regime[i]=rex(redes['Mu-'][i],redes['Mu+'][i])\n",
    "redes['Regime']=regime\n",
    "del redes['Fitted']\n",
    "del redes['Mu-']\n",
    "del redes['Mu+']\n",
    "\n",
    "###Filling NaNs\n",
    "#redes.fillna(0,inplace=True)\n",
    "\n",
    "###Renaming columns and getting rid of the networkx graph\n",
    "redes=redes[['Subject ID','Subject origin','Subject residence','Mu','Regime','Average degree','Betweenness',\n",
    "             'Closeness','Load centrality','Assortativity','Clustering',\n",
    "             'Number components','Size largest component',\n",
    "             'Closeness residence','Number residence','Closeness origin','Number origin','Graphs']]\n",
    "del redes['Graphs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More changes in the networks dataframe and merging \n",
    "\n",
    "Now we are going to merge the network measures dataframe with the original one _df_, that contains information about egos and alteris. We want to preserve the egos attributes, so we delete all the information about the alteris. We will also introduce the variable _FMIG2_ that measures the number of years these migrants have spent in their residence countries. Once we have made all these changes, some typos need to be corrected, and that is what we do at the end of this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Deleting the alteri column in df and merging it with the networks dataframe\n",
    "df.drop([\"alter/origin\",\"alter/residence\",\"alter/num\"],axis=1,inplace=True)\n",
    "df.drop([col for col in df.columns if col[0] == \"A\"],axis=1,inplace=True)\n",
    "df.rename(columns={'sub/num':'Subject ID','sub/origin':'Subject origin','sub/residence':'Subject residence'},inplace=True)\n",
    "df = df.drop_duplicates(['Subject origin','Subject ID'])\n",
    "\n",
    "redes2= pd.merge(redes, df,how='left',on=['Subject ID','Subject origin','Subject residence'])\n",
    "redes2.drop(\"Subject ID\",axis=1,inplace=True)\n",
    "\n",
    "###Calculating FMIG2\n",
    "import datetime\n",
    "FMIG2=[0]*len(redes2)\n",
    "for i in range(len(redes2)):\n",
    "    if (redes2['FMIG'].iloc[i]<0.5): \n",
    "        FMIG2[i]=0\n",
    "    elif (redes2['FMIG'].iloc[i]>1500):\n",
    "        FMIG2[i] = 2005 - redes2['FMIG'].iloc[i]\n",
    "redes2['FMIG2']=FMIG2\n",
    "redes2.drop(\"FMIG\",axis=1,inplace=True)\n",
    "\n",
    "###Renaming columns and changing some typos\n",
    "redes2.rename(columns={'Subject origin':'Subject_origin','Subject residence':'Subject_residence'},inplace=True)\n",
    "redes2.columns = redes2.columns.str.replace(' ', '_')\n",
    "redes2.dropna(axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the final results and display a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "redes2.to_csv(\"Redes_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject_origin</th>\n",
       "      <th>Subject_residence</th>\n",
       "      <th>Mu</th>\n",
       "      <th>Regime</th>\n",
       "      <th>Average_degree</th>\n",
       "      <th>Betweenness</th>\n",
       "      <th>Closeness</th>\n",
       "      <th>Load_centrality</th>\n",
       "      <th>Assortativity</th>\n",
       "      <th>Clustering</th>\n",
       "      <th>...</th>\n",
       "      <th>TIEDEN</th>\n",
       "      <th>TIEDC</th>\n",
       "      <th>TIECC</th>\n",
       "      <th>TIEBC</th>\n",
       "      <th>TIECND</th>\n",
       "      <th>TIECCZ</th>\n",
       "      <th>DSET</th>\n",
       "      <th>sub/language</th>\n",
       "      <th>alter_language</th>\n",
       "      <th>FMIG2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>do</td>\n",
       "      <td>sp</td>\n",
       "      <td>0.011112</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>31.600000</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>0.801154</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>-0.199161</td>\n",
       "      <td>0.684147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25253</td>\n",
       "      <td>75.84205</td>\n",
       "      <td>43.82789</td>\n",
       "      <td>9.15293</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>l1d</td>\n",
       "      <td>es</td>\n",
       "      <td>es</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>se</td>\n",
       "      <td>sp</td>\n",
       "      <td>0.089195</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>12.533333</td>\n",
       "      <td>0.017285</td>\n",
       "      <td>0.590461</td>\n",
       "      <td>0.017212</td>\n",
       "      <td>-0.255307</td>\n",
       "      <td>0.552218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.15758</td>\n",
       "      <td>87.48616</td>\n",
       "      <td>71.56298</td>\n",
       "      <td>51.49595</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>l3bs</td>\n",
       "      <td>es</td>\n",
       "      <td>es</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>do</td>\n",
       "      <td>sp</td>\n",
       "      <td>0.503703</td>\n",
       "      <td>Standard</td>\n",
       "      <td>29.954545</td>\n",
       "      <td>0.007404</td>\n",
       "      <td>0.780109</td>\n",
       "      <td>0.007404</td>\n",
       "      <td>0.007975</td>\n",
       "      <td>0.801524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.54343</td>\n",
       "      <td>42.39257</td>\n",
       "      <td>44.19432</td>\n",
       "      <td>4.76352</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>l1d</td>\n",
       "      <td>es</td>\n",
       "      <td>es</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>se</td>\n",
       "      <td>sp</td>\n",
       "      <td>-0.325123</td>\n",
       "      <td>Inverted</td>\n",
       "      <td>23.600000</td>\n",
       "      <td>0.016655</td>\n",
       "      <td>0.615225</td>\n",
       "      <td>0.016655</td>\n",
       "      <td>0.499006</td>\n",
       "      <td>0.830791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53636</td>\n",
       "      <td>48.52009</td>\n",
       "      <td>35.27839</td>\n",
       "      <td>11.53614</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>l1s</td>\n",
       "      <td>es</td>\n",
       "      <td>es</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>ar</td>\n",
       "      <td>sp</td>\n",
       "      <td>-0.263139</td>\n",
       "      <td>Inverted</td>\n",
       "      <td>8.454545</td>\n",
       "      <td>0.042399</td>\n",
       "      <td>0.372683</td>\n",
       "      <td>0.042396</td>\n",
       "      <td>0.103047</td>\n",
       "      <td>0.750587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.15253</td>\n",
       "      <td>86.58537</td>\n",
       "      <td>714.25538</td>\n",
       "      <td>23.80011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>lba</td>\n",
       "      <td>es</td>\n",
       "      <td>es</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>do</td>\n",
       "      <td>sp</td>\n",
       "      <td>0.066795</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>0.767192</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>-0.141919</td>\n",
       "      <td>0.649453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.35556</td>\n",
       "      <td>67.44186</td>\n",
       "      <td>77.93953</td>\n",
       "      <td>11.68847</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>l3bd</td>\n",
       "      <td>es</td>\n",
       "      <td>es</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>do</td>\n",
       "      <td>usa</td>\n",
       "      <td>0.275320</td>\n",
       "      <td>Standard</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>-0.022727</td>\n",
       "      <td>0.676638</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08384</td>\n",
       "      <td>93.09309</td>\n",
       "      <td>79.60957</td>\n",
       "      <td>30.71690</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>rc2f1de</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>do</td>\n",
       "      <td>usa</td>\n",
       "      <td>-0.044483</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.022727</td>\n",
       "      <td>0.868196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.62626</td>\n",
       "      <td>39.11205</td>\n",
       "      <td>48.85972</td>\n",
       "      <td>1.49565</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>rcfds</td>\n",
       "      <td>es</td>\n",
       "      <td>es</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>ar</td>\n",
       "      <td>sp</td>\n",
       "      <td>-0.215321</td>\n",
       "      <td>Inverted</td>\n",
       "      <td>15.727273</td>\n",
       "      <td>0.013670</td>\n",
       "      <td>0.574877</td>\n",
       "      <td>0.013668</td>\n",
       "      <td>-0.155336</td>\n",
       "      <td>0.750841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.29293</td>\n",
       "      <td>72.64673</td>\n",
       "      <td>8578.10745</td>\n",
       "      <td>32.64296</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>l5da</td>\n",
       "      <td>es</td>\n",
       "      <td>es</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>do</td>\n",
       "      <td>usa</td>\n",
       "      <td>-0.044483</td>\n",
       "      <td>Unclear</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.022727</td>\n",
       "      <td>0.984412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.95657</td>\n",
       "      <td>4.54545</td>\n",
       "      <td>6.86379</td>\n",
       "      <td>0.99466</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>rdfds</td>\n",
       "      <td>es</td>\n",
       "      <td>es</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Subject_origin Subject_residence        Mu    Regime  Average_degree  \\\n",
       "405             do                sp  0.011112   Unclear       31.600000   \n",
       "447             se                sp  0.089195   Unclear       12.533333   \n",
       "348             do                sp  0.503703  Standard       29.954545   \n",
       "422             se                sp -0.325123  Inverted       23.600000   \n",
       "226             ar                sp -0.263139  Inverted        8.454545   \n",
       "380             do                sp  0.066795   Unclear       30.000000   \n",
       "76              do               usa  0.275320  Standard       44.000000   \n",
       "22              do               usa -0.044483   Unclear       44.000000   \n",
       "209             ar                sp -0.215321  Inverted       15.727273   \n",
       "30              do               usa -0.044483   Unclear       44.000000   \n",
       "\n",
       "     Betweenness  Closeness  Load_centrality  Assortativity  Clustering  ...  \\\n",
       "405     0.006554   0.801154         0.006554      -0.199161    0.684147  ...   \n",
       "447     0.017285   0.590461         0.017212      -0.255307    0.552218  ...   \n",
       "348     0.007404   0.780109         0.007404       0.007975    0.801524  ...   \n",
       "422     0.016655   0.615225         0.016655       0.499006    0.830791  ...   \n",
       "226     0.042399   0.372683         0.042396       0.103047    0.750587  ...   \n",
       "380     0.007400   0.767192         0.007400      -0.141919    0.649453  ...   \n",
       "76      0.003271   1.000000         0.000070      -0.022727    0.676638  ...   \n",
       "22      0.000000   1.000000         0.000000      -0.022727    0.868196  ...   \n",
       "209     0.013670   0.574877         0.013668      -0.155336    0.750841  ...   \n",
       "30      0.000000   1.000000         0.000000      -0.022727    0.984412  ...   \n",
       "\n",
       "      TIEDEN     TIEDC       TIECC     TIEBC  TIECND  TIECCZ     DSET  \\\n",
       "405  0.25253  75.84205    43.82789   9.15293    11.0    0.70      l1d   \n",
       "447  0.15758  87.48616    71.56298  51.49595     8.0    0.83     l3bs   \n",
       "348  0.54343  42.39257    44.19432   4.76352    29.0    0.83      l1d   \n",
       "422  0.53636  48.52009    35.27839  11.53614    28.0    0.85      l1s   \n",
       "226  0.15253  86.58537   714.25538  23.80011     1.0    0.71      lba   \n",
       "380  0.35556  67.44186    77.93953  11.68847    12.0    0.78     l3bd   \n",
       "76   0.08384  93.09309    79.60957  30.71690     2.0    0.91  rc2f1de   \n",
       "22   0.62626  39.11205    48.85972   1.49565    17.0    0.93    rcfds   \n",
       "209  0.29293  72.64673  8578.10745  32.64296    12.0    0.83     l5da   \n",
       "30   0.95657   4.54545     6.86379   0.99466     3.0   -0.89    rdfds   \n",
       "\n",
       "    sub/language alter_language  FMIG2  \n",
       "405           es             es    1.0  \n",
       "447           es             es    6.0  \n",
       "348           es             es    1.0  \n",
       "422           es             es    0.0  \n",
       "226           es             es    0.0  \n",
       "380           es             es    2.0  \n",
       "76            en             en    0.0  \n",
       "22            es             es    0.0  \n",
       "209           es             es    3.0  \n",
       "30            es             es    0.0  \n",
       "\n",
       "[10 rows x 106 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redes2.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
