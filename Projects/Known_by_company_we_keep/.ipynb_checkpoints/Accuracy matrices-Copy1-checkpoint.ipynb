{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "156a9203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-27 16:50:12.464752: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-27 16:50:12.464774: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import roc_auc_score,classification_report,confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "from itertools import product\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "799d0219",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_embeddings = pd.read_csv(\"total_embeddings_with_bf_p1q10_courses.csv\")\n",
    "total_embeddings.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
    "total_embeddings[\"Escuela\"] = total_embeddings[\"Escuela\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f65c1dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_courses = len(total_embeddings.loc[(total_embeddings[\"class_classif\"]!=\"Missing\")&(total_embeddings[\"class_classif\"]!=\"Intergroup\"),[\"Escuela\",\"class_classif\"]].value_counts())\n",
    "unique_schools = total_embeddings[\"Escuela\"].nunique()\n",
    "factor = 10\n",
    "n_sim = unique_courses*factor #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae381228",
   "metadata": {},
   "source": [
    "### Standard prediction, random chosen at the edges for each high school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "672b2e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ba709b114a4898a0cc682ea9bdcbb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-27 16:50:18.903783: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-27 16:50:18.903811: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-27 16:50:18.903834: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (iT28200): /proc/driver/nvidia/version does not exist\n",
      "2022-05-27 16:50:18.904027: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "acc_clf_auc = np.zeros((n_sim))\n",
    "acc_ann_auc = np.zeros((n_sim))\n",
    "for i in tqdm(range(n_sim)):\n",
    "    tr_label = i%unique_schools\n",
    "    X = total_embeddings[total_embeddings[\"Escuela\"] == tr_label].drop([\"Escuela\",\"weight\",'class_classif'],axis=1).values\n",
    "    y = total_embeddings[total_embeddings[\"Escuela\"] == tr_label][\"weight\"].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    sc = MinMaxScaler()\n",
    "    sc.fit(X_train)\n",
    "    emb_x_train = sc.transform(X_train)\n",
    "    emb_y_train = y_train\n",
    "    emb_x_test = sc.transform(X_test)\n",
    "    emb_y_test = y_test\n",
    "    ros = SMOTE(random_state=0,sampling_strategy=\"minority\")\n",
    "    emb_x_resampled, emb_y_resampled = ros.fit_resample(emb_x_train, emb_y_train)\n",
    "    clf = RandomForestClassifier(max_depth=7,class_weight=\"balanced\")\n",
    "    clf.fit(emb_x_resampled,emb_y_resampled)\n",
    "    acc_clf_auc[int(i)] = roc_auc_score(emb_y_test,clf.predict(emb_x_test))\n",
    "    #######\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(128,activation=\"relu\",input_shape=(emb_x_train.shape[1],)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(64,activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(32,activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(8,activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=10e-5),\n",
    "             loss=\"binary_crossentropy\",\n",
    "                 metrics=[\"AUC\"])\n",
    "    model_history = model.fit(emb_x_resampled,emb_y_resampled,epochs=250,verbose=0,batch_size=128,\n",
    "                             #callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"auc\",patience=50,)])\n",
    "                             )\n",
    "    #######ยบ\n",
    "    acc_ann_auc[int(i)] = roc_auc_score(emb_y_test,model.predict(emb_x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817a63d2",
   "metadata": {},
   "source": [
    "### Saving the AUC result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49491ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"acc_clf_auc\",\"acc_ann_auc\"]\n",
    "with open(\"p1q10_accuracies_global_nsim_randomized.txt\", \"w\") as f:\n",
    "    for i,lista in enumerate([acc_clf_auc,acc_ann_auc]):\n",
    "        f.write(names[i]+\"\\n\")\n",
    "        for elem in lista:\n",
    "            f.write(str(elem) +\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495c586f",
   "metadata": {},
   "source": [
    "### Visualization of auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d93bcee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************\n",
      "The mean is 0.747 for the Random Forest and the std is 0.019\n",
      "The mean is 0.772 for the Random Forest and the std is 0.039\n"
     ]
    }
   ],
   "source": [
    "print(\"************************\")\n",
    "print(f\"The mean is {np.mean(acc_clf_auc) :2.3f} for the Random Forest and the std is {np.std(acc_clf_auc) :2.3f}\")\n",
    "print(f\"The mean is {np.mean(acc_ann_auc) :2.3f} for the Random Forest and the std is {np.std(acc_ann_auc) :2.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ea92cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c942b6dac042b5b705728419bf381c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_clf_auc_classes = np.zeros((n_sim))\n",
    "acc_ann_auc_classes = np.zeros((n_sim))\n",
    "k_group = 0\n",
    "for i in tqdm(range(unique_schools*factor)):\n",
    "    tr_label = i%unique_schools\n",
    "    grupos = list(total_embeddings[total_embeddings[\"Escuela\"] == tr_label][\"class_classif\"].unique())\n",
    "    if \"Intergroup\" in grupos:\n",
    "        grupos.remove(\"Intergroup\")\n",
    "    if \"Missing\" in grupos:\n",
    "        grupos.remove(\"Missing\")\n",
    "    for grupo in grupos:\n",
    "        X = total_embeddings[total_embeddings[\"Escuela\"] == tr_label].drop([\"Escuela\",\"weight\"],axis=1)\n",
    "        y = total_embeddings[total_embeddings[\"Escuela\"] == tr_label][[\"weight\",\"class_classif\"]]\n",
    "        X_train = X[X[\"class_classif\"] != grupo].drop(\"class_classif\",axis=1).values\n",
    "        X_test = X[X[\"class_classif\"] == grupo].drop(\"class_classif\",axis=1).values\n",
    "        y_train = y[y[\"class_classif\"] != grupo].drop(\"class_classif\",axis=1).values\n",
    "        y_test = y[y[\"class_classif\"] == grupo].drop(\"class_classif\",axis=1).values\n",
    "        sc = MinMaxScaler()\n",
    "        sc.fit(X_train)\n",
    "        emb_x_train = sc.transform(X_train)\n",
    "        emb_y_train = y_train\n",
    "        emb_x_test = sc.transform(X_test)\n",
    "        emb_y_test = y_test\n",
    "        ros = SMOTE(random_state=0,sampling_strategy=\"minority\")\n",
    "        emb_x_resampled, emb_y_resampled = ros.fit_resample(emb_x_train, emb_y_train)\n",
    "        clf = RandomForestClassifier(max_depth=7,class_weight=\"balanced\")\n",
    "        clf.fit(emb_x_resampled,emb_y_resampled)\n",
    "        try:\n",
    "            acc_clf_auc_classes[k_group] = roc_auc_score(emb_y_test,clf.predict(emb_x_test))\n",
    "        except:\n",
    "            acc_clf_auc_classes[k_group] = \"Homogeneous\"\n",
    "        #######\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(128,activation=\"relu\",input_shape=(emb_x_train.shape[1],)),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(64,activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(32,activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(8,activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
    "        ])\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=10e-5),\n",
    "                 loss=\"binary_crossentropy\",\n",
    "                     metrics=[\"AUC\"])\n",
    "        model_history = model.fit(emb_x_resampled,emb_y_resampled,epochs=250,verbose=0,batch_size=128,\n",
    "                                 #callbacks=[tf.keras.callbacks.EarlyStopping(patience=50)])\n",
    "                                 )\n",
    "        #######ยบ\n",
    "        try:\n",
    "            acc_ann_auc_classes[k_group] = roc_auc_score(emb_y_test,model.predict(emb_x_test))\n",
    "        except:\n",
    "            acc_ann_auc_classes[k_group] = \"Homogeneous\"\n",
    "        k_group += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f4a66f",
   "metadata": {},
   "source": [
    "total_elem = []\n",
    "for lista in acc_clf_auc_classes:\n",
    "    for elem in lista:\n",
    "        if elem != \"Homogeneous\":\n",
    "            total_elem.append(elem)\n",
    "print(f\"La media es {np.mean(total_elem) :3.2f} y la std es {np.std(total_elem):3.2f} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c52a241",
   "metadata": {},
   "source": [
    "total_elem_2 = []\n",
    "for lista in acc_ann_auc_classes:\n",
    "    for elem in lista:\n",
    "        if elem != \"Homogeneous\":\n",
    "            total_elem_2.append(elem)\n",
    "print(f\"La media es {np.mean(total_elem_2) :3.2f} y la std es {np.std(total_elem_2):3.2f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9946bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"acc_clf_auc_classes\",\"acc_ann_auc_classes\"]\n",
    "with open(\"p1q0_accuracies_courses_nsim_randomized.txt\", \"w\") as f:\n",
    "    for i,lista in enumerate([acc_clf_auc_classes,acc_ann_auc_classes]):\n",
    "        f.write(names[i]+\"\\n\")\n",
    "        for elem in lista:\n",
    "            f.write(str(elem) +\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
