{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce0f0e15",
   "metadata": {},
   "source": [
    "In this notebook we produce an embedding using the technique of Node2vec similar to Word2vec (linguistic models). \n",
    "With this node embedding we compute the edge embedding and make a k-cross validation score against the weighted edges\n",
    "of the network. \n",
    "The goal is to produce an embedding of edges that, given two nodes, provides the predicted sign of the link. \n",
    "For this purpose we have substituted the classes in the edges by only 2, positive and negative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b30228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "import torch\n",
    "import torch_geometric.data as data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch_geometric.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import negative_sampling,train_test_split_edges,to_dense_adj\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from sklearn import preprocessing\n",
    "from torch_geometric.nn import Node2Vec\n",
    "\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c218f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.read_csv(r\"Nodes_t1.csv\",sep=\";\",encoding = 'unicode_escape')\n",
    "edges = pd.read_csv(r\"Edges_t1.csv\",sep=\";\",encoding = 'unicode_escape')\n",
    "edges[\"weight\"] = edges[\"weight\"].apply(lambda x: np.sign(x))\n",
    "edges[[\"from\",\"to\"]] = edges[[\"from\",\"to\"]].apply(lambda x: x - x.min(),axis = 0)\n",
    "###Erase ESO \n",
    "nodes[\"Curso\"] = nodes[\"Curso\"].astype(str).str[0].astype(\"int64\")\n",
    "del nodes[\"Unnamed: 0\"]\n",
    "nodes_dummy = pd.get_dummies(nodes)\n",
    "x = nodes_dummy.values \n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "nodes_norm = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df35c6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = data.Data(x=torch.tensor(nodes_norm.to_numpy(),dtype=torch.float32),\n",
    "                          edge_index=torch.tensor(edges[[\"from\",\"to\"]].to_numpy().T),\n",
    "                          edge_attr=torch.tensor((pd.get_dummies(edges[\"weight\"]).to_numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0ee618e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[409, 11], edge_index=[2, 8557], edge_attr=[8557, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e996994c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "# get the nodes\n",
    "nodes = total_data.edge_index.t().numpy()\n",
    "nodes = np.unique(list(nodes[:,0]) + list(nodes[:,1]))\n",
    "\n",
    "np.random.shuffle(nodes) # shuffle node order\n",
    "print(len(nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36c4a9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286 61 62\n"
     ]
    }
   ],
   "source": [
    "# get train test and val sizes: (70% - 15% - 15%)\n",
    "train_size = int(len(nodes)*0.7)\n",
    "test_size = int(len(nodes)*0.85) - train_size\n",
    "val_size = len(nodes) - train_size - test_size\n",
    "print(train_size,test_size,val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f10bbb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286 61 62\n",
      "True\n",
      "train set\t [299 161   1 105  97 113 226 146 102 329]\n",
      "test set \t [ 95  67  96  22 254 244 318 159 316 144]\n",
      "val set  \t [250 289 284 203 135 145 390  71 118 365]\n"
     ]
    }
   ],
   "source": [
    "train_set = nodes[0:train_size]\n",
    "test_set = nodes[train_size:train_size+test_size]\n",
    "val_set = nodes[train_size+test_size:]\n",
    "\n",
    "\n",
    "print(len(train_set),len(test_set),len(val_set))\n",
    "print(len(train_set)+len(test_set)+len(val_set) == len(nodes))\n",
    "\n",
    "print(\"train set\\t\",train_set[:10])\n",
    "print(\"test set \\t\",test_set[:10])\n",
    "print(\"val set  \\t\",val_set[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d4482ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mask \t tensor([1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0])\n",
      "test mask  \t tensor([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1])\n",
      "val mask   \t tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "# build test train val masks\n",
    "\n",
    "train_mask = torch.zeros(len(nodes),dtype=torch.long, device=device)\n",
    "for i in train_set:\n",
    "    train_mask[i] = 1.\n",
    "\n",
    "test_mask = torch.zeros(len(nodes),dtype=torch.long, device=device)\n",
    "for i in test_set:\n",
    "    test_mask[i] = 1.\n",
    "    \n",
    "val_mask = torch.zeros(len(nodes),dtype=torch.long, device=device)\n",
    "for i in val_set:\n",
    "    val_mask[i] = 1.\n",
    "    \n",
    "print(\"train mask \\t\",train_mask[0:15])\n",
    "print(\"test mask  \\t\",test_mask[0:15])\n",
    "print(\"val mask   \\t\",val_mask[0:15]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d461630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after\t\t Data(x=[409, 11], edge_index=[2, 8557], edge_attr=[8557, 2], train_mask=[409], test_mask=[409], val_mask=[409])\n"
     ]
    }
   ],
   "source": [
    "# add masks\n",
    "total_data.train_mask = train_mask\n",
    "total_data.test_mask = test_mask\n",
    "total_data.val_mask = val_mask\n",
    "\n",
    "print(\"after\\t\\t\",total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ac32a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = Node2Vec(total_data.edge_index, embedding_dim=128, walk_length=70,\n",
    "             context_size=50, walks_per_node=10,\n",
    "             num_negative_samples=1, p=1, q=1, sparse=True).to(device)\n",
    "\n",
    "loader = model.loader(batch_size=128, shuffle=True, num_workers=4)\n",
    "optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a935ea21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 4.2172\n",
      "Epoch: 20, Loss: 2.5879\n",
      "Epoch: 30, Loss: 1.7538\n",
      "Epoch: 40, Loss: 1.3596\n",
      "Epoch: 50, Loss: 1.1608\n",
      "Epoch: 60, Loss: 1.0597\n",
      "Epoch: 70, Loss: 0.9882\n",
      "Epoch: 80, Loss: 0.9679\n",
      "Epoch: 90, Loss: 0.9570\n",
      "Epoch: 100, Loss: 0.9299\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    z = model()\n",
    "    acc = model.test(z[total_data.train_mask], total_data.y[total_data.train_mask],\n",
    "                     z[total_data.test_mask], total_data.y[total_data.test_mask],\n",
    "                     max_iter=10)\n",
    "    return acc\n",
    "\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    #acc = test()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "609337b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42cec562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensor to numpy\n",
    "emb_128 = z.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ac8b9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical edge attributes:\n",
      " [[1 0]\n",
      " [1 0]\n",
      " [0 1]]\n",
      "\n",
      "\n",
      "Numerical edge attributes:\n",
      " [0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# convert edge attributes from categorical to numerical\n",
    "edge_attr_cat = total_data.edge_attr.numpy()\n",
    "print(\"Categorical edge attributes:\\n\",edge_attr_cat[:3])\n",
    "\n",
    "edge_attr = []\n",
    "for i in edge_attr_cat:\n",
    "    edge_attr.append(np.nonzero(i)[0][0])\n",
    "\n",
    "print(\"\\n\\nNumerical edge attributes:\\n\",edge_attr[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd427513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute edge embedding\n",
    "\n",
    "edge_embedding = []\n",
    "for u,v in total_data.edge_index.t():\n",
    "    edge_embedding.append(np.mean([emb_128[u],emb_128[v]],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94848c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13582002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524174728097502"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=7,random_state=10)\n",
    "\n",
    "\n",
    "scores = cross_val_score(clf, edge_embedding, total_data.edge_attr, cv=10)\n",
    "np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f59bbcfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=7, random_state=10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(edge_embedding,total_data.edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "460896c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[1]*128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35511885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7302"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([i[1] for i in total_data.edge_attr.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8dd796d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.029328987341954"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)/(1-(1255/7302))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7737e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
