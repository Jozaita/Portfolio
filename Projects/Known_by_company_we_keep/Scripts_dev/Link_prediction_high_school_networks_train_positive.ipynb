{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebfa7cb5",
   "metadata": {},
   "source": [
    "## Training the GNN with the 80% of the positive network and testing on the remaining\n",
    "\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df969c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "import torch\n",
    "import torch_geometric.data as data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch_geometric.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import negative_sampling,train_test_split_edges,to_dense_adj\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from sklearn import preprocessing\n",
    "\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5283f3c3",
   "metadata": {},
   "source": [
    "### Create networks and standarize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7712e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "## Just prepare the data\n",
    "nodes = pd.read_csv(r\"Nodes_t1.csv\",sep=\";\",encoding = 'unicode_escape')\n",
    "edges = pd.read_csv(r\"Edges_t1.csv\",sep=\";\",encoding = 'unicode_escape')\n",
    "edges = edges.apply(lambda x: x - x.min(),axis = 0)\n",
    "###Erase ESO \n",
    "nodes[\"Curso\"] = nodes[\"Curso\"].astype(str).str[0].astype(\"int64\")\n",
    "del nodes[\"Unnamed: 0\"]\n",
    "edges[\"weight\"] = edges[\"weight\"].apply(lambda x:x+1)\n",
    "pos_edges = edges[edges[\"weight\"]> 3]\n",
    "neg_edges = edges[edges[\"weight\"]< 3]\n",
    "### One hot encode and normalize node attributes\n",
    "nodes_dummy = pd.get_dummies(nodes[[\"Curso\",\"Grupo\"]])\n",
    "rng = np.random.default_rng()\n",
    "#nodes_dummy = pd.DataFrame(rng.integers(0, 2, size=(409, 10)), columns=list('ABCDEFGHIJ'))\n",
    "\n",
    "x = nodes_dummy.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "nodes_norm = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865fd432",
   "metadata": {},
   "source": [
    "### Split G_positive into a G_positive_train and G_positive_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "529aead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df = pos_edges.sample(frac=1)\n",
    "len_train_set = int(len(shuffled_df)*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aae7ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_train = pos_edges[:len_train_set]\n",
    "edges_test = pos_edges[len_train_set:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c2627a",
   "metadata": {},
   "source": [
    "### Define the complementary network of the training network (for the null model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fded0872",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_real = []\n",
    "for elem in edges_train[[\"from\",\"to\"]].to_numpy():\n",
    "    edges_real.append(tuple(elem))\n",
    "chosen_edges = list(nx.complete_graph(409,create_using=nx.DiGraph()).edges())\n",
    "for elem in edges_real:\n",
    "    chosen_edges.remove(elem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28ba8f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.Data(x=torch.tensor(nodes_norm.to_numpy(),dtype=torch.float32),\n",
    "                          edge_index=torch.tensor(edges_train[[\"from\",\"to\"]].to_numpy().T))\n",
    "test_data = data.Data(x=torch.tensor(nodes_norm.to_numpy(),dtype=torch.float32),\n",
    "                          edge_index=torch.tensor(edges_train[[\"from\",\"to\"]].to_numpy().T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ad389ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/.local/lib/python3.8/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "data = train_data.clone()\n",
    "data.num_nodes = len(data._store[\"x\"])\n",
    "data = train_test_split_edges(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce89d8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(data.num_features, 128)\n",
    "        self.conv2 = GCNConv(128, 64)\n",
    "\n",
    "    def encode(self):\n",
    "        x = self.conv1(data.x, data.train_pos_edge_index) # convolution 1\n",
    "        x = x.relu()\n",
    "        return self.conv2(x, data.train_pos_edge_index) # convolution 2\n",
    "\n",
    "    def decode(self, z, pos_edge_index, neg_edge_index): # only pos and neg edges\n",
    "        edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=-1) # concatenate pos and neg edges\n",
    "        logits = (z[edge_index[0]] * z[edge_index[1]]).sum(dim=-1)  # dot product \n",
    "        return logits\n",
    "\n",
    "    def decode_all(self, z): \n",
    "        prob_adj = z @ z.t() # get adj NxN\n",
    "        return (prob_adj > 1-10e-10).nonzero(as_tuple=False).t() # get predicted edge_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9082f44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, data = Net().to(device), data.to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17029a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_link_labels(pos_edge_index, neg_edge_index):\n",
    "    # returns a tensor:\n",
    "    # [1,1,1,1,...,0,0,0,0,0,..] with the number of ones is equel to the lenght of pos_edge_index\n",
    "    # and the number of zeros is equal to the length of neg_edge_index\n",
    "    E = pos_edge_index.size(1) + neg_edge_index.size(1)\n",
    "    link_labels = torch.zeros(E, dtype=torch.float, device=device)\n",
    "    link_labels[:pos_edge_index.size(1)] = 1.\n",
    "    return link_labels\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=data.train_pos_edge_index, #positive edges\n",
    "        num_nodes=data.num_nodes, # number of nodes\n",
    "        num_neg_samples=data.train_pos_edge_index.size(1)) # number of neg_sample equal to number of pos_edges\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    z = model.encode() #encode\n",
    "    link_logits = model.decode(z, data.train_pos_edge_index, neg_edge_index) # decode\n",
    "    \n",
    "    link_labels = get_link_labels(data.train_pos_edge_index, neg_edge_index)\n",
    "    loss = F.binary_cross_entropy_with_logits(link_logits, link_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    perfs = []\n",
    "    for prefix in [\"val\", \"test\"]:\n",
    "        pos_edge_index = data[f'{prefix}_pos_edge_index']\n",
    "        neg_edge_index = data[f'{prefix}_neg_edge_index']\n",
    "\n",
    "        z = model.encode() # encode train\n",
    "        link_logits = model.decode(z, pos_edge_index, neg_edge_index) # decode test or val\n",
    "        link_probs = link_logits.sigmoid() # apply sigmoid\n",
    "        \n",
    "        link_labels = get_link_labels(pos_edge_index, neg_edge_index) # get link\n",
    "        \n",
    "        perfs.append(roc_auc_score(link_labels.cpu(), link_probs.cpu())) #compute roc_auc score\n",
    "    return perfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "767726ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss: 0.4510, Val: 0.9488, Test: 0.9189\n",
      "Epoch: 200, Loss: 0.4283, Val: 0.9545, Test: 0.9193\n",
      "Epoch: 300, Loss: 0.4297, Val: 0.9561, Test: 0.9185\n",
      "Epoch: 400, Loss: 0.4288, Val: 0.9561, Test: 0.9185\n",
      "Epoch: 500, Loss: 0.4287, Val: 0.9561, Test: 0.9185\n",
      "Epoch: 600, Loss: 0.4150, Val: 0.9561, Test: 0.9185\n",
      "Epoch: 700, Loss: 0.4161, Val: 0.9561, Test: 0.9185\n",
      "Epoch: 800, Loss: 0.4113, Val: 0.9561, Test: 0.9185\n",
      "Epoch: 900, Loss: 0.4125, Val: 0.9561, Test: 0.9185\n",
      "Epoch: 1000, Loss: 0.4042, Val: 0.9561, Test: 0.9185\n"
     ]
    }
   ],
   "source": [
    "best_val_perf = test_perf = 0\n",
    "for epoch in range(1, 1001):\n",
    "    train_loss = train()\n",
    "    val_perf, tmp_test_perf = test()\n",
    "    if val_perf > best_val_perf:\n",
    "        best_val_perf = val_perf\n",
    "        test_perf = tmp_test_perf\n",
    "    log = 'Epoch: {:03d}, Loss: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
    "    if epoch % 100 == 0:\n",
    "        print(log.format(epoch, train_loss, best_val_perf, test_perf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1bee029",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model.encode()\n",
    "final_edge_index_1 = model.decode_all(z)\n",
    "#Remove self loops\n",
    "bool_mask = final_edge_index_1[0] != final_edge_index_1[1]\n",
    "simulated_edges_1 = torch.empty((2,int(sum(bool_mask))))\n",
    "for item in range(final_edge_index_1.size()[0]):\n",
    "    simulated_edges_1[item] = final_edge_index_1[item][bool_mask]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "451d3a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coincidences = to_dense_adj(test_data[\"edge_index\"]).squeeze()*to_dense_adj(final_edge_index_1).squeeze()\n",
    "coin_GNN = coincidences.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21099e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[409, 9], edge_index=[2, 5841])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coin_GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0996609f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The GNN obtains a 86.87% of accuracy in predicting links, but as in the previous case producing a big amount of them.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The GNN obtains a {coin_GNN/test_data.edge_index.size()[1]*100:.2f}% of accuracy in predicting links, but as in the previous case producing a big amount of them.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "639ed1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_test = nx.from_pandas_edgelist(edges_test, \"from\", \"to\",create_using=nx.DiGraph,edge_attr=\"weight\")\n",
    "import random as rd \n",
    "coincidences_total = 0\n",
    "for sim in range(10):\n",
    "    chosen_edges_2 = chosen_edges.copy()\n",
    "    G_random = nx.DiGraph()\n",
    "    G_random.add_nodes_from(range(409))\n",
    "    for trial in range(final_edge_index_1.size()[1]):\n",
    "        rd_sample = rd.choice(chosen_edges_2)\n",
    "        G_random.add_edge(rd_sample[0],rd_sample[1]) \n",
    "        chosen_edges_2.remove(rd_sample)\n",
    "    coincidences_random = len([(u,v) for (u,v) in G_random.edges() if G_test.has_edge(u,v)])\n",
    "    coincidences_total += coincidences_random\n",
    "coin_random = coincidences_total/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53d01c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The null model obtains a 3.50% of accuracy in predicting links, but as in the previous case producing a big amount of them.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The null model obtains a {coin_random/test_data.edge_index.size()[1]*100:.2f}% of accuracy in predicting links, but as in the previous case producing a big amount of them.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cedb437d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5074.), 22112)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coin_GNN,len(simulated_edges_1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b79d7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
